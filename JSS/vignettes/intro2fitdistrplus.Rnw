%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Copyright (c) 2012 Marie Laure Delignette-Muller, Christophe Dutang                        
%                                                                                                                                                       
%    This program is free software; you can redistribute it and/or modify                               
%    it under the terms of the GNU General Public License as published by                        
%    the Free Software Foundation; either version 2 of the License, or                                 
%    (at your option) any later version.                                                                                        
%                                                                                                                                                      
%    This program is distributed in the hope that it will be useful,                                          
%    but WITHOUT ANY WARRANTY; without even the implied warranty of                        
%    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the                   
%    GNU General Public License for more details.                                                                    
%                                                                                                                                                         
%    You should have received a copy of the GNU General Public License                           
%    along with this program; if not, write to the                                                                            
%    Free Software Foundation, Inc.,                                                                                             
%    59 Temple Place, Suite 330, Boston, MA 02111-1307, USA                                            
%                                                                                                                                                         
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Fit parametric distributions on non-censored or censored data with fitdistrplus
%%%
%%%         Sweave vignette file
%%%

\documentclass[a4paper]{article}
% sweave commands for vignette
%\VignetteIndexEntry{Fit parametric distributions on non-censored or censored data}
%\VignettePackage{fitdistrplus}
%\VignetteKeyword{distribution}


%American Mathematical Society (AMS) math symbols
\usepackage{amsfonts,amssymb,amsmath}

% accents 8 bits dans le fichier
%\usepackage[applemac]{inputenc} %MAC encoding
\usepackage[utf8]{inputenc} %UNIX encoding
%\usepackage[ansinew]{inputenc} %WINDOWS encoding

% sans cette ligne ajoutee pour l'encodage des polices, les apostrophes generees par R
% dans les sorties ne sont pas reconnues sur mon PC (windows 7, 64 bits)
\usepackage[T1]{fontenc}

\usepackage{color,graphics, wrapfig, subfig}
\usepackage[a4paper, textwidth=18cm, textheight=27cm]{geometry}
\usepackage{url}

%reference hypertext
\usepackage[hyperfootnotes=false]{hyperref}

%todo notes
\usepackage{todonotes}


% les macros generales

%layout
\newcommand{\HRuleTop}{\noindent\rule{\linewidth}{.5pt}}
\newcommand{\HRuleBottom}{\rule{\linewidth}{.5pt}}
\newcommand{\ligne}{\rule[2mm]{.3\textwidth}{0,5mm}\\}
\newcommand{\myskip}{\vspace{\parskip}}
\newcommand{\mytodo}[1]{\todo[color=green]{TODO}#1}
\newcommand{\blank}{ \clearpage{\pagestyle{empty}\cleardoublepage} }


%text style (some are common with the JSS latex class)
\newcommand{\pkg}{\textbf}
\newcommand{\sigle}{\textsc}
\newcommand{\code}{\texttt}
\newcommand{\proglang}{\textsf}
\newcommand{\txtm}[1]{\textrm{~~#1~~}}
\newcommand{\expo}{\textsuperscript}



\title{Fitting parametric univariate distributions  to non-censored or
censored data using the \proglang{R} package \pkg{fitdistrplus}}
\author{Marie Laure Delignette-Muller and Christophe Dutang}

\begin{document}
\SweaveOpts{concordance=TRUE, prefix.string=figs/intro}
\setkeys{Gin}{width=0.8\textwidth} %equivalent to \includegraphics[width=0.8\textwidth]{.}

\maketitle


\HRuleTop\\
The package \pkg{fitdistrplus} provides functions for fitting univariate distributions
on different types of data (continuous censored or non-censored data and discrete data) and allowing
different estimation methods (maximum likelihood, moment matching, quantile matching
and maximum goodness-of-fit estimation).
Outputs of \code{fitdist} and \code{fitdistcens} functions are S3 objects, for
which kind generic methods are provided, including \code{summary}, \code{plot} and
\code{quantile}. 
This package also provides various functions to compare the fit of several distributions to a same data set 
and can handle bootstrap of parameter estimates.
Detailed examples are given in food risk assessment, ecotoxicology and insurance contexts. 
\\
\textit{Keywords}: probability distribution fitting, bootstrap, censored data, maximum likelihood, moment matching, 
quantile matching, maximum goodness-of-fit.
\\
\HRuleBottom


% A enlever dans version JSS !
%\tableofcontents


%\newpage


\section{Introduction}
\label{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



Fitting distributions to data is a very common task in statistics and consists in choosing
a probability distribution that gives a good representation of a statistical
variable, as well as finding parameter estimates of that distribution. 
It requires judgment and expertise and generally needs an iterative process of
distribution choice, parameter estimation, and quality of fit assessment.
The \code{fitdistr} function in the \proglang{R} package \pkg{MASS} (\cite{MASS}) 
is a well known general-purpose maximum-likelihood
fitting routine for the parameter estimation step in \proglang{R} \cite{R12}. Other steps of
the process may be developed using \proglang{R}, e.g. \cite{Ricci05}. 
In this paper, we present our \proglang{R} package \pkg{fitdistrplus} (\cite{fitdistrplus})
implementing several methods of fitting univariate parametric distribution.
Our first objective by developping this package was to provide \proglang{R} 
users a set of functions dedicated to help this overall process.

The \code{fitdistr} function estimates distribution parameters by maximizing the log-likelihood
using the \code{optim} function. 
In some cases, other estimation methods could be prefered, 
such as maximum goodness-of-fit estimation (also called minimum distance estimation), and
proposed in the \proglang{R} package \pkg{actuar} with three different goodness-of-fit distances, 
see \cite{actuarJSS}. 
While developping  the \pkg{fitdistrplus} package, our second objective  was thus to extend function \code{fitdistr} 
by providing various estimation methods in addition to maximum likelihood estimation (MLE). Functions
were developped to enable moment matching estimation (MME), quantile matching estimation (QME), and 
maximum goodness-of-fit estimation (MGE) using eight different distances.
Moreover, the \pkg{fitdistrplus} package offers the possibility to specify a user-supplied function
for optimization, 
useful in cases where classical optimization techniques not included in \code{optim} are more adequate.

In applied statistics, it is frequent to have to fit distributions to censored data \cite{kleinmoeschberger03,
helsel05,busschaertetal10,lehaetal11,commeauetal12}. 
The \pkg{MASS} \code{fitdistr} function 
does not enable maximum likelihood estimation with this type data. Some packages 
deal with censored data, especially survival data \cite{survival} (see \cite{hiranoetal94,jordan05}
for examples),
but those packages generally focused on specific models, enabling the fit of only one distribution or a 
restricted family of distributions. 
Our third objective was thus to provide \proglang{R} users a function 
to estimate univariate distribution parameters from censored data, whatever the type of censoring. 
% je pense que deux références suffisent?
% ou qui tout simplement ne les prennent pas en compte comme il faut
% ex.: Hickey 2012, Fox 2010, Buschaert ????, ...
% EXPLORER LES REF SUIVANTES en microbio et en chercher en ecotox et ailleurs
% -Pouillot et al. (2007) Quantitative Risk Assessment of Listeria monocytogenes in French cold-smoked salmon: I. Quantitative exposure assessment. Risk Analysis 27, 683-700. + Beaufort et al. (2007) Prevalence and growth of Listeria monocytogenes in naturally contaminated cold-smoked salmon. Lett Appl Microbiol 44, 406-411. 


Few packages on \sigle{CRAN} provide estimation procedures for a general distribution and a general type of data. 
The \pkg{distrMod} package of \cite{distrModJSS} provides an object-oriented (S4) 
implementation of probability models 
and includes distribution fitting procedures for a given minimization criterion.
In \pkg{fitdistrplus}, we use the standard S3 class system, we believe simpler than the full object-oriented S4 model for most \proglang{R} users.
Furthermore, the \pkg{distrMod} package does not allow to fit censored data.
The \code{mle} function of \pkg{stats4} package provides a procedure for maximum likelihood estimation whose output has class \code{"mle"}.
Many generic methods are implemented for this type of object, e.g. \code{confint}, \code{logLik},...
When designing the \pkg{fitdistrplus} package, we also take this into account.
Finally, various other packages provide functions to estimate the mode, the moments or the L-moments of a distribution, see the reference manuals of  \pkg{modeest}, \pkg{lmomco} and \pkg{Lmoments} packages.

This manuscript reviews the various features of version 1.0-1 of \pkg{fitdistrplus}. The package
is available from the Comprehensive \proglang{R} Archive Network at \url{http://cran.r-project.org/package=fitdistrplus}.
The development version of the package is located at \proglang{R}-forge as one the packages of the 
project ``Risk Assessment with R''
(\url{http://r-forge.r-project.org/projects/riskassessment/}).
The following command will load the package.
%%% R code set default options for all R schunks
<<par4vignette, echo=FALSE, results=hide>>=
options(digits=4, SweaveHooks=list(fig=function() par(mar=c(5.1, 4.1, 1.1, 2.1))) )
@
%%% R code
<<pkgload1, results=hide>>=
library(fitdistrplus)
@
The paper is organized as follows: Section \ref{fitnoncenscont} present tools for fitting continuous
distributions to classic non-censored data. Section \ref{advtopic} deals with other
estimation methods and other types of data, before Section \ref{ccl} concludes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Fitting distributions to continuous non-censored data\label{fitnoncenscont}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Choice of candidate distributions}
\label{Choice}
For illustrating the use of various functions of the \pkg{fitdistrplus} package 
with continuous non-censored data, we   first use
a data set named \code{groundbeef} which is included in our package.
This data set contains pointwise values of
serving sizes in grams, collected in a French survey, for ground beef patties consumed by 
children under 5 years old. It was used in a quantitative risk assessment 
published in the international journal of food microbiology journal \cite{Delignette08}.
%%% R code
<<datgroundbeef, echo=TRUE>>=
data(groundbeef)
str(groundbeef)
@

Before fitting one or more distributions to a data set, it is generally
necessary to choose good candidates among a predefined family of distributions.
This choice may be guided by the knowledge of stochastic processes governing
the modelled variable, but also by the observation of its empirical distribution.
To help the user in this choice, we developed functions to plot and
characterise the empirical distribution.

First of all, the empirical distribution  function and the histogram may be plotted using the 
classical \proglang{R} functions \code{ecdf} and \code{hist}, 
or by using the \code{plotdist} function of the \pkg{fitdistrplus} package.
This function provides two plots (see Figure 1): the left-hand graph is the histogram (on a density level) 
and the right-hand graph plots the empirical cumulative distribution function (CDF).
%%% R code
<<figgroundbeef.echo, echo=TRUE, fig=FALSE, eval=FALSE>>=
plotdist(groundbeef$serving)
@
\begin{figure}[htb!]
  \centering
  %%% R code
<<figgroundbeefplot, echo=FALSE, fig=TRUE, width=10, height=5, eps=FALSE>>=
plotdist(groundbeef$serving)
@
  \caption{Histogram and CDF plots of an empirical distribution for a continuous variable 
  (serving size from the \code{groundbeef} data set)}
  \label{plotdistcont}
\end{figure}



In addition to empirical plots, descriptive statistics may help to choose good candidates to describe a distribution
among a family of parametric distributions. Especially the skewness and kurtosis, linked to the third and fourth moments, 
are useful for this purpose. A non-zero skewness reveals a lack of symmetry of the empirical distribution,
while the kurtosis value quantifies the weight of tails in comparison to the normal distribution for which
the kurtosis equals 3.
%The concept of skewness relates to deviations from symmetry of the distribution is defined as
%The normal distribution has a skewness of zero. 
%A positive (resp. negative) skewness indicates 
%that the right (resp. left) tail of the distribution is more extended than the left (resp. right) one.
% The concept of kurtosis relates to the tail weight. The normal distribution has a kurtosis of 3.
%Distributions with a higher kurtosis are said to be leptokurtic, with heavier tails, such as the 
%logistic distribution, while distributions with a smaller kurtosis are said platykurtic, with lighter 
%tails, such as the uniform distribution.
The skewness and kurtosis and their corresponding unbiased estimator from a sample 
$(X_i)_i \stackrel{\text{i.i.d.}}{\sim} X$ with observations $(x_i)_i$ are given by
  \begin{equation}
    \label{skewness}
    sk(X) = \frac{E[(X-E(X))^3]}{Var(X)^{\frac{3}{2}}}~,~
    \widehat{sk}=\frac{\sqrt{n(n-1)}}{n-2}\times\frac{m_{3}}{m_{2}^{\frac{3}{2}}},
  \end{equation}

  \begin{equation}
    \label{kurtosis}
    kr(X) = \frac{E[(X-E(X))^4]}{Var(X)^{2}}~,~
    \widehat{kr}=\frac{n-1}{(n-2)(n-3)}((n+1) \times \frac{m_{4}}{m_{2}^{2}}-3(n-1)) + 3,
  \end{equation}
where $m_{2}$, $m_{3}$, $m_{4}$ denote empirical moments defined by
$m_{r}=\frac{1}{n}\sum_{i=1}^n(x_{i}-\overline{x})^{r}$, with
$x_{i}$ the $n$ observations of variable $x$ and $\overline{x}$ their mean value.

The  \code{descdist} function provides calculations of classical descriptive statistics
(minimum, maximum, median, mean, standard deviation), skewness and kurtosis. By default, 
unbiased estimations of the three last statistics are provided. But, the argument \code{method}
may be used to obtain  them without correction for bias. 
A skewness-kurtosis plot such as the one proposed by \cite{Cullen99} is  provided by 
the function \code{descdist} for the empirical distribution 
(see Figure~\ref{Cullenplotcont} for the \code{groundbeef} data set). 
On this plot, values for common distributions are displayed in order 
to help the choice of distributions to fit to data. For some distributions (normal, uniform,
logistic, exponential), there is only one possible value for the skewness and the kurtosis.
 Thus, the distribution is represented by a single point on the plot. For other distributions, 
areas of possible values are represented, consisting in lines (as for gamma and lognormal distributions), 
or larger areas (as for beta distribution).
    
Skewness and kurtosis are known not to be robust. In order to take into account the uncertainty 
of the estimated values of kurtosis and skewness from data, a bootstrap procedure can be performed
by fixing the argument \code{boot} to an integer above 10.
Bootstrap samples of the same size of the original data set
are then constructed by random sampling with replacement from that original data set.
Values of skewness and kurtosis are computed on that bootstrap samples and reported on the 
skewness-kurtosis plot. Below is a call to the \code{descdist} function to describe the distribution 
of the serving size from the \code{groundbeef} data set and to draw the corresponding skewness-kurtosis
plot (see Figure~\ref{Cullenplotcont}). Looking at the results on this example
with a positive skewness and a kurtosis not far from 3,
the fit of three common right-skewed distributions could be considered, Weibull, gamma and 
lognormal distributions.
%%% R code
<<descgroundbeef.echo, echo=TRUE, fig=FALSE, eval=FALSE>>=
descdist(groundbeef$serving, boot=1000)
@
%pourquoi boot=100 ne suffirait pas?

% pourquoi changer ces parametres en cours de route?
\setkeys{Gin}{width=0.5\textwidth}

\begin{figure}[htb]
  \centering
 %%% R code
<<descgroundbeefplot, echo=FALSE, fig=TRUE, width=6, height=6, eps=FALSE>>=
descdist(groundbeef$serving, boot=1000)
@
  \caption{Skewness-kurtosis plot for a continuous variable 
  (serving size from the \code{groundbeef} data set)}
  \label{Cullenplotcont}
\end{figure}


\setkeys{Gin}{width=0.8\textwidth} %default
%\clearpage

Together with the use of the \code{plotdist} and \code{descdist} functions to characterize  the empirical distribution,
the properties of the modeled variable should be considered, especially its range. 
Having chosen good candidates for the distribution, we turn to the fit of distributions and comparison of goodness-of-fits.

\subsection{Fit of distributions by maximum likelihood estimation}
\label{FIT}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Once selected, one or more parametric distributions $f(.\vert \theta)$ may be fitted to the data set, 
one at a time, using the \code{fitdist} function. 
Under the i.i.d. sample assumption, distribution parameters $\theta$ are by default estimated by maximizing the
likelihood defined as:
  \begin{equation}
    \label{likelihood}
    L(\theta)=\prod_{i=1}^n f(x_{i}\vert \theta)
  \end{equation}
with $x_{i}$ the $n$ observations of variable $X$ and $f(.\vert \theta)$ the density function of the 
parametric distribution.
The other proposed estimation methods are described in Section~\ref{Alternatives}. 

The \code{fitdist} function returns the results of the fit of any parametric distribution 
to a data set as an S3 class object that may be easily printed, 
summarized or plotted. 
In order to be used in \code{fitdist}, a distribution \code{dist} must be defined by
the \code{d}, \code{p}, \code{q} functions, standing respectively for the density, 
the cumulative distribution and the quantile functions, e.g.
\code{dnorm}, \code{pnorm} and \code{qnorm} for the normal distribution.  
The name of the fitted distribution is specified in the first argument by its classical 
abbreviation \code{dist} used in the \code{d}, \code{p}, \code{q} functions, e.g. \code{"norm"}
for the normal distribution. Numerical results returned by the \code{fitdist} function are 
(1) the parameter estimates, (2) the estimated standard errors (computed from the estimate
of the Hessian matrix at the maximum likelihood solution), (3) the loglikelihood, (4) Akaike and Schwarz information criteria (the so-called AIC and BIC), and (5) the correlation matrix
between parameter estimates.
Below is a call to the \code{fitdist} function to fit a Weibull distribution 
to the serving size from the \code{groundbeef} data set.
%%% R code
<<fitgroundbeef.weibull, echo = TRUE, fig = FALSE>>=
fw <- fitdist(groundbeef$serving, "weibull")
summary(fw)
@

The plot of an object of class \code{"fitdist"} provides 
four classical goodness-of-fit plots \cite{Cullen99}: 
\begin{itemize}
\item a density plot representing the density function of the fitted distribution 
along with the histogram of the empirical distribution, 
\item a CDF plot of both the empirical distribution and the fitted distribution, 
\item a Q-Q plot
representing the empirical quantiles (y-axis) against the theoretical quantiles (x-axis)
\item a P-P plot representing the empirical distribution function evaluated at each data point (y-axis)
against the fitted distribution function (x-axis).
\end{itemize}

Unlike \code{plot.fitdist}, the \code{denscomp}, \code{cdfcomp},
\code{qqcomp} and \code{ppcomp} functions enable to separately plot each
of these four plots, in order to compare the empirical and multiple theoretical distributions fitted
on a same data set. These functions must be called with a first argument 
corresponding to a list of objects of class \code{fitdist}, and optionaly
further arguments to customize the plot (see the reference 
manual~\cite{fitdistrplus} for lists of arguments that may be changed
for each plot). 
In the following example, we compare the fit of
a Weibull, a lognormal and a gamma distributions to the \code{groundbeef} data set (Figure~\ref{groundbeef:comp}).
%%% R code
<<fitgroundbeef.echo, echo=TRUE, fig=FALSE>>=
fg <- fitdist(groundbeef$serving,"gamma")
fln <- fitdist(groundbeef$serving,"lnorm")
par(mfrow=c(2, 2))
denscomp(list(fw,fln,fg), legendtext=c("Weibull", "lognormal", "gamma"))
qqcomp(list(fw,fln,fg), legendtext=c("Weibull", "lognormal", "gamma"))
cdfcomp(list(fw,fln,fg), legendtext=c("Weibull", "lognormal", "gamma"))
ppcomp(list(fw,fln,fg), legendtext=c("Weibull", "lognormal", "gamma"))
@

\begin{figure}[htb!]
  \centering
<<fitgroundbeef, echo=FALSE, fig=TRUE, width=7, height=7, eps=FALSE>>=
fg <- fitdist(groundbeef$serving,"gamma")
fln <- fitdist(groundbeef$serving,"lnorm")
par(mfrow=c(2, 2))
denscomp(list(fw,fln,fg), legendtext=c("Weibull", "lognormal", "gamma"))
qqcomp(list(fw,fln,fg), legendtext=c("Weibull", "lognormal", "gamma"))
cdfcomp(list(fw,fln,fg), legendtext=c("Weibull", "lognormal", "gamma"))
ppcomp(list(fw,fln,fg), legendtext=c("Weibull", "lognormal", "gamma"))
@ 
  \caption{Four Goodness-of-fit plots for various distributions fitted on continuous data
  (Weibull, gamma and lognormal
  distributions fitted to serving sizes from the \code{groundbeef} data set)}
\label{groundbeef:comp}  
\end{figure}


For CDF, Q-Q and P-P plots, the probability plotting position is defined by default using the Hazen's rule, with probability points of the empirical distribution defined as
 \code{(1:n - 0.5)/n}, as recommended by Blom \cite{Blom}.
This plotting position can be easily changed using the arguments 
\code{use.ppoints} and \code{a.ppoints}. When \code{use.ppoints = TRUE}, 
the argument \code{a.ppoints} is passed to the \code{ppoints} function from the \pkg{stats} package to define the 
probability points of the empirical distribution as \code{(1:n - a.ppoints)/(n - 2a.ppoints + 1)}. 
When \code{use.ppoints = FALSE}, the probability points are simply defined as \code{1:n / n}.

The density plot and the CDF plot are the most classical goodness-of-fits plots. The two other plots
are complementary and can be very informative in some cases.
The Q-Q plot emphasizes the lack-of-fit at the distribution tails while the P-P plot emphasizes
the lack-of-fit at the distribution center.
As an example in Figure~\ref{groundbeef:comp}, none of the three fitted distributions describes
the center of the distribution rather better than the two others, but the Weibull and gamma distributions 
should be prefered for their better description of the right tail of the empirical distribution, especially
if the weight of this tail is important in the use of the fitted distribution, as it is in the context of
food risk assessment.


To illustrate other features of the \pkg{fitdistrplus} package, we will now use another
data set named  \code{endosulfan}, which is included in our package. This data set contains
acute toxicity values for the organochlorine pesticide endosulfan
(geometric mean of LC50 ou EC50 values in $\mu g.L^{-1}$),
tested on Australian and non-Australian laboratory-species 
(arthropods, fish or nonarthropod invertebrates, see \cite{Hose04}). 
<<datendosulfan, echo=TRUE>>=
data(endosulfan)
str(endosulfan)
@

In ecotoxicology, a
lognormal or a loglogistic distribution is often fitted to such a data set in order
to characterize the species sensitivity distribution (SSD) for a pollutant. A low percentile
of the fitted distribution, generally the 5$\%$ percentile, is calculated and named the hazardous concentration 5$\%$ (HC5).
It is interpreted as the value of the
pollutant concentration protecting 95$\%$ of the species.
But the fit of a lognormal or a loglogistic distribution to the whole \code{endosulfan} data set is rather bad,
especially due to a minority of very high values. We can try to fit this data set by the Pareto distribution or the three-parameter Burr distribution which is an extension
of both the loglogistic and the Pareto distribution. Pareto and Burr distributions
are provided in package \pkg{actuar}. 
Until here, we did not have to implicity define starting values (in the optimization process)
as reasonable starting values are defined within function \code{fitdist}
for most of the distributions defined in \proglang{R} packages (see the help of \code{fitdist} for details).
For other distributions like the Pareto and the Burr distribution, we have to supply initial 
values for the distribution parameters in the argument \code{start} when using the maximum likelihood method.
\code{start} must be a named list  with initial values for each parameter (as they appear in the \code{d},
\code{p}, \code{q} functions). 
Having defined reasonable starting values\footnote{The  \code{plotdist} function can plot any parametric distribution with specified parameter values
in argument \code{para}. It can thus help to find correct initial values for 
the distribution parameters in non trivial cases, by iterative calls if necessary (see the reference 
manual~\cite{fitdistrplus} for examples).
}, we can fit various distributions and graphically
compare their fits. On this example, the use of functions \code{cdfcomp} and
\code{qqcomp} is especially interesting to evaluate the goodness-of-fit on the tail of
interest while defining an $HC5$ value.

%%% R code
<<fitendo.echo, echo=TRUE, fig=FALSE>>=
ATV <-endosulfan$ATV
fendo.ln <- fitdist(ATV, "lnorm")
library(actuar)
fendo.ll <- fitdist(ATV, "llogis", start=list(shape=1, scale=500))
fendo.P <- fitdist(ATV, "pareto", start=list(shape=1, scale=500))
fendo.B <- fitdist(ATV, "burr", start=list(shape1=0.3, shape2=1, rate=1))
par(mfrow=c(1, 2))
cdfcomp(list(fendo.ln, fendo.ll, fendo.P, fendo.B), xlogscale=TRUE,
          legendtext = c("lognormal","loglogistic","Pareto","Burr"))
qqcomp(list(fendo.ln, fendo.ll, fendo.P, fendo.B), xlogscale=TRUE, ylogscale=TRUE,
       legendtext = c("lognormal","loglogistic","Pareto","Burr"))
@

\begin{figure}[htb!]
  \centering
<<fitendo, echo=FALSE, fig=TRUE, width=7, height=3.5, eps=FALSE>>=
par(mfrow=c(1, 2))
cdfcomp(list(fendo.ln,fendo.ll,fendo.P,fendo.B),xlogscale=TRUE,
          legendtext = c("lognormal","loglogistic","Pareto","Burr"))
qqcomp(list(fendo.ln,fendo.ll,fendo.P,fendo.B),xlogscale=TRUE,ylogscale=TRUE,
       legendtext = c("lognormal","loglogistic","Pareto","Burr"))
@  
  \caption{CDF and Q-Q plots to compare the fit of four distributions to
  acute toxicity values of various organisms for the organochlorine pesticide endosulfan
  (\code{endosulfan} data set)}
\label{endo:comp}  
\end{figure}

We can see in Figure~\ref{endo:comp} that none of the fitted distribution correctly
describes the right tail observed in the data set. 
But  the left tail seems to be better described by the Burr distribution. Its use could then be considered
to estimate the $HC5$ value as the $5\%$ quantile of the distribution. This can be 
easily done using the \code{quantile} generic function defined for an object 
of class \code{"fitdist"}. Below is this calculation together with the calculation of the 
empirical quantile for comparison.
%%% R code
<<quantilefitdist, echo=TRUE, fig=FALSE>>=
quantile(fendo.B, probs = 0.05)
quantile(ATV, probs = 0.05)
@

% A ENLEVER %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
% Keep only for the vignette
%For a pedagogic purpose, here is a fit of a user-supplied distribution. 
%We fit the Gumbel distribution 
%(also named the extreme value distribution) on the \code{groundbeef} data set.
%<<fitdanish1, echo=TRUE, fig=FALSE>>=
%dgumbel<-function(x,a,b) 1/b*exp((a-x)/b)*exp(-exp((a-x)/b))
%pgumbel<-function(q,a,b) exp(-exp((a-q)/b))
%qgumbel<-function(p,a,b) a-b*log(-log(p))
%summary(fitdist(groundbeef$serving, "gumbel", start=list(a=5, b=10)))
%@

%\begin{figure}[htb]
%  \centering
%<<echo=FALSE, results=hide, fig=TRUE>>=
%plotdist(x1,"gumbel",para=list(a=10,b=5))
%@
%  \caption{Preliminar plot of a distribution against data to find initial values for parameters}
%  \label{plotdist}
%\end{figure}


%%% R code
%<<fitgroundbeef.weibull.echo, echo=TRUE, fig=FALSE, eval=FALSE>>=
%plot(fw)
%@
%\setkeys{Gin}{width=0.65\textwidth} %default
%\begin{figure}[htb]
%  \centering
%  %%% R code
%<<fitgroundbeefweibullplot, echo=FALSE, fig=TRUE, width=7, height=7, eps=FALSE>>=
%plot(fw)
%@
%  \caption{Plot of the fit of a continuous distribution (a Weibull
%  distribution fitted to serving sizes from the \code{groundbeef} data set)}
%  \label{plotcontfit}
%\end{figure}


%\subfloat[Densities]{ 
% %%% R code
%<<fittoxocarapoisnbinomplot, echo=FALSE, fig=TRUE, width=4, height=4, eps=FALSE>>=
%    denscomp(list(fw,fln,fg),legendtext=c("Weibull","lognormal","gamma"),
%    xlab="serving sizes (g)",lwd=2)
%@
%\label{compdens}}
%  \caption{Comparison of density plots of various distributions fitted on continuous data
%  (Weibull, gamma and lognormal
%  distributions fitted to serving sizes from the ``ground beef'' data set)}
%  \label{compdens}
%\end{figure}
%
%\begin{figure}[htb]
%  \centering
  
%  \subfloat[CDFs]{ 
%  %%% R code
%<<fittoxocarapoisnbinomcdfcomp, echo=FALSE, fig=TRUE, width=4, height=4, eps=FALSE>>=
%    cdfcomp(list(fw,fln,fg), legendtext=c("Weibull","lognormal","gamma"),
%    	xlab="serving sizes (g)", lwd=2)
%@
%\label{compcdf} }


%\setkeys{Gin}{width=0.8\textwidth} %default


%In such a plot, data may be represented in a log scale when required, by just fixing the argument
%\texttt{xlogscale} to \texttt{TRUE} in the call to \texttt{cdfcomp}.
% completer avec tout ce qu'on peut changer dans cdfcomp : PAS FORCEMENT UTILE

%\clearpage


To go further in the comparison of various distributions, we propose
the calculation of different goodness-of-fit statistics in our package.
The purpose of goodness-of-fit statistics aims to measure the distance between the
fitted parametric distribution and the empirical distribution: e.g. 
the distance between the fitted cumulative distribution function $F$ 
and the empirical distribution function $F_{n}$.
When fitting continuous distributions, three  goodness-of-fit statistics are classicaly considered: 
Cramer-von Mises, Kolmogorov-Smirnov and Anderson-Darling statistics.
Naming $x_{i}$ the $n$ observations of a continuous variable $X$ arranged in an ascending order,
Table \ref{tabKSCvMAD} gives the definition and the empirical estimate of the three considered 
goodness-of-fit statistics.

\begin{table}[htb!]
  \begin{center}
    \caption{Goodness-of-fit statistics as defined by Stephens \cite{Stephens86}.}
    \begin{tabular}{lll}
    \hline
      Statistic  & General formula & Computational formula\\
    \hline
      Kolmogorov-Smirnov   & $\sup|F_{n}(x) - F(x)|$ &
      $\max(D^{+},D^{-})$ with\\
      (KS)&& $D^{+}=\max\limits_{i=1,\dots,n}\left(\frac{i}{n} - F(x_{i})\right)
      ;D^{-}=\max\limits_{i=1,\dots,n}\left(F(x_{i})-\frac{i-1}{n}\right)$ \\
    \hline
      Cramer-von Mises  & n $\int_{-\infty}^{\infty}(F_{n}(x) - F(x))^2 dx$ &
        $\frac{1}{12n} + \sum\limits_{i=1}^n \left(F(x_{i})-\frac{2i-1}{2n} \right)^{2}$\\
      (CvM)&&\\
% cvm <- 1/(12*n) + sum( ( theop - (2 * seq(1:n) - 1)/(2 * n) )^2 )
    \hline
      Anderson-Darling  & n $\int_{-\infty}^{\infty}\frac{(F_{n}(x) - F(x))^2}{F(x) (1 - F(x))} dx$
      & $-n -\frac{1}{n}\sum\limits_{i=1}^n \left((2i-1)(\log(F(x_{i}))+\log(1-F(x_{n+1-i})) )\right)$ \\
      (AD) &    & \\
% ad <- - n - mean( (2 * seq(1:n) - 1) * (log(theop) + log(1 - rev(theop))) )
    \hline
    \end{tabular}
    \label{tabKSCvMAD}
  \end{center}
\end{table}

They can be computed using the function \code{gofstat}
as defined by Stephens \cite{Stephens86}.

<<fendo.gof.print, echo=TRUE, fig=FALSE>>=
gofstat(list(fendo.ln, fendo.ll, fendo.P, fendo.B))
@
As giving  more weight to distribution tails, 
Anderson-Darling statistics is of special interest when it matters to equally 
emphasize the tails as well as the main body of a distribution.
This is often the case in risk assessment, e.g. \cite{Cullen99,Vose10}. For this reason, 
this statistics is often used to select the best distribution among those fitted.
Nevertheless, this statistics should be used cautiously when comparing fits of various distributions. 
We must keep in mind that the weighting of each CDF quadratic difference 
depends on the theoretical distribution in its definition, see Table \ref{tabKSCvMAD}.
Anderson-Darling statistics computed for several distributions fitted on a same data set
are thus theoretically difficult to compare. Moreover, such a statistic, as Cramer-von Mises and
Kolmogorov-Smirnov ones, does not take into account the complexity of the model. It is not
a problem when compared distributions are characterized by the same number of parameters, but
it could systematically promote the selection of the more complex distributions in the other case. 
Looking at classical penalized criteria based on the loglikehood seems thus also interesting, especially
to discourage overfitting. 

In the previous example, all the goodness-of-fit statistics based on the cdf distance encourage the choice of 
the Burr distribution, the only one characterized by three parameters, while Akaike and Schwarz information criteria 
(so called AIC and BIC) respectively gives the preference to the Burr distribution or the Pareto distribution.
The choice between these two distributions seems thus less obvious and could be discussed. 
Even if specifically recommended for discrete distributions, the Chi-squared statistic may also be used for
continuous distributions (see Section~\ref{otherdata} and the reference 
manual~\cite{fitdistrplus} for examples).


%For continuous distributions, an approximate Kolmogorov-Smirnov test is 
%performed by assuming the distribution parameters known. The critical value defined by Stephens~\cite{Stephens86} 
%for a completely specified distribution is used to reject or not the 
%distribution at the significance level 0.05. Because of this approximation, the result of the test
%(decision of rejection of the distribution or not) is returned only for data sets with more 
%than 30 observations. Note that this approximate test may be too conservative. 

%For data sets with more than 5 observations and for continuous distributions for 
%which the test is described by Stephens~\cite{Stephens86} for maximum likelihood
%estimations (exponential, Cauchy, gamma and Weibull),
%the Cramer-von Mises and Anderson-darling tests are performed as described by Stephens~\cite{Stephens86}. 
%Those tests take into 
%account the fact that the parameters are not known but estimated from the data. The result is the 
%decision to reject or not the distribution at the significance level 0.05. Both tests are available
%only for maximum likelihood estimations.

%When the Chi-squared statistic is computed (for discrete or optionnaly continuous distributions), 
%and if the degree of freedom (nb of cells - nb of parameters - 1)  of the corresponding distribution 
%is strictly positive, the p-value of the Chi-squared test is returned.

%The results of the tests are not printed, unless the argument \code{print.test}
%is set to \code{TRUE}. We chose not to print their results by default, as 
%goodness-of-fit tests are often misused. As for any null-hypothesis significance
%test, the non reject of the null hypothesis dose not imply its acceptation. However, this
%misinterpretation of p-values is very common and comes from the wrong assumption that
%absence of evidence is evidence of absence ~\cite{Altman96}.
%On the contrary, in some cases, especially on very big data sets, 
%even if the null hypothesis is rejected, a fitted distribution may be 
%chosen as the best one among simple distributions to describe an empirical distribution, if the goodness-of-fit
%plots do not show strong differences between empirical and theoretical distributions.

%Now let us look at the Chi-squared test results for the fit of a negative binomial distribution 
%to ``toxocara'' data set :
%<<echo=TRUE,fig=FALSE>>=
%gofstat(fnb,print.test = TRUE)
%@

%A warning message appears as one of the theoretical counts is under 5 using the default breaks 
%(see Section~\ref{GOF:measures}). In order to solve this problem, one may specify breaks 
%more adapted for the realization of the test.
%<<echo=TRUE,fig=FALSE>>=
%gofstat(fnb,chisqbreaks=c(0,1,4,8,20),print.test=TRUE)$chisqtable
%@

%From goodness-of-fit graphs, Chi-squared statistics, AIC and BIC values,
%it seems better to choose the fit of a negative binomial distribution
%for this data set even it has one more parameter than the Poisson one. This was not obvious while
%looking at the skewness-kurtosis graph. This graph must be used cautiously especially for continuous 
%distributions far from the normal distribution or for discrete distributions. It is only indicative.

%\clearpage

\subsection{Uncertainty in parameter estimates}
\label{Uncertainty}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The uncertainty in the parameters of the fitted distribution may be simulated by parametric or nonparametric
bootstraps using the \code{boodist} function for non-censored data.
% and by nonparametric bootstrap using \code{boodistcens} function for censored data. 
This function returns the bootstrapped values of parameters in a 
S3 class object which
may be plotted to visualize the bootstrap region. 
The medians and the 95 percent confidence intervals of parameters (2.5 and 97.5 percentiles) are printed 
in the summary.
If inferior to the whole number of iterations, the number of iterations for which the function converges 
is also printed in the summary.
    
The plot of an object of class \code{"bootdist"}  
% or \code{"bootdistcens"}
 consists in a scatterplot or a matrix of scatterplots
of the bootstrapped values of parameters providing
a representation of the joint uncertainty distribution of the fitted parameters (see Figure~\ref{fig:bootstrap}).
Below is an example of the use of the \code{bootdist} function with the previous fit of the Burr distribution to the
\code{endosulfan} data set. 
%%% R code
<<fitBurr.boot.echo, echo=TRUE, fig=FALSE>>=
bendo.B <- bootdist(fendo.B, niter=1001)
summary(bendo.B)
plot(bendo.B)
@

%Then we fit the three-parameter distribution of Burr on \code{danishuni} data set.
%As when fitting the Pareto type II distribution, we have to use a lower bound when
%carrying out the optimization.
%Otherwise \code{optim} do not converge.
%<<fitdanish.burr.boot.echo, echo=TRUE, fig=FALSE>>=
%fdan <- fitdist(danishuni$Loss, "burr", method="mle", 
%  start=c(shape1=5, shape2=5, rate=10), lower=1e-1)
%bdan <- bootdist(fdan,  bootmethod="param", niter=101)
%summary(bdan)
%plot(bdan)
@

\setkeys{Gin}{width=0.5\textwidth} %default


\begin{figure}[htb!]
  \centering
  \subfloat{
  %%% R code
<<fitBurrbootplot, echo=FALSE, fig=TRUE, width=6, height=6, eps=FALSE>>=
plot(bendo.B)
@
}

% enleve car empechait la compilation du tex
%\subfloat{
  %%% R code
%<<fitdanishburrbootplot, echo=FALSE, fig=TRUE, width=6, height=6, eps=FALSE>>=
%plot(bdan)
%@
%}
  \caption{Bootstrappped values of parameters for a fit of the Burr distribution
characterized by three parameters (example on the \code{endosulfan} data set)}
  \label{fig:bootstrap}
\end{figure}


Bootstrap samples of parameter estimates are useful especially to calculate confidence intervals on each parameter
of the fitted distribution from the marginal distribution of the bootstraped values. It is also interesting to look at the joint distribution of the bootstraped
values in a scatterplot (or a matrix of scatterplots if the number of parameters exceeds two) in order
to understand the potential structural correlation between parameters (see Figure~\ref{fig:bootstrap}).

The use of the whole bootstrap sample is also of interest in the risk assessment field. Its use enables
the characterization of uncertainty in distribution parameters. 
It can be directly used within a second-order Monte Carlo
simulation framework, especially within the package \pkg{mc2d} (\cite{mc2d}). One could refer to Pouillot \emph{et al.}
(\cite{Pouillot10}) for an introduction to the use of \pkg{mc2d} 
and \pkg{fitdistrplus} packages in the context of quantitative 
risk assessment.

Bootstrap can also be used to calculate confidence intervals on quantiles of the fitted distribution.
For this purpose, a generic \code{quantile} function is provided for class \code{bootdist}. 
%It must be called with a first argument corresponding
%to an object of class \code{bootdist} or \code{fitdistcens}, and as a second argument the vector of probabilities
%at which the quantiles of the fitted distribution must be estimated. 
By default $95\%$ bootstrap confidence intervals of quantiles are provided.
Going back to the previous example from ecotoxicolgy, this function can be used to 
estimate the uncertainty associated to the HC5 estimation, for example from the previously fitted
Burr distribution to the \code{endosulfan} data set.
 %%% R code
<<fitATV.lnorm.quantile, echo=TRUE>>=
quantile(bendo.B, probs = 0.05)
@




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Advanced topics\label{advtopic}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Alternative methods for parameter estimation}
\label{Alternatives}

Despite maximum likelihood estimation is the default estimation proposed by 
\code{fitdist}, other classical estimation methods can be handled to estimate parameters for non-censored data.
Thus, this subsection focuses on alternative estimation methods.



%\subsubsection{Maximum goodness-of-fit estimation}
%\label{MGE}
%%%%%%%%%%
One of the alternative for continuous distributions
is the maximum goodness-of-fit estimation method also called
minimum distance estimation method. In this package this method is proposed with
eight different distances: the three classical distances defined
in Table~\ref{tabKSCvMAD},
or one of the variants of the Anderson-Darling distance proposed by \cite{Luceno06} and defined in 
Table~\ref{modifiedAD}.
The right-tail AD gives more weight only to the right tail, the left-tail AD
gives more weight only to the left tail. Either of the tails, or both of them,
can receive even larger
weights by using second order Anderson-Darling Statistics.

\begin{table}[htb!]
  \begin{center}
    \caption{Modified Anderson-Darling statistics as defined by Luceno \cite{Luceno06}.}
    \begin{tabular}{lll}
    \hline
      Statistic  & General formula & Computational formula\\
    \hline
      Right-tail AD  & $\int_{-\infty}^{\infty}\frac{(F_{n}(x) - F(x))^2 }{1 - F(x)}  dx$
      & $\frac{n}{2} -2\sum_{i}F(x_{i}) -\frac{1}{n}\sum_{i}((2i-1)ln(1-F(x_{n+1-i})))$ \\
      (ADR) &  &\\
    \hline
      Left-tail AD  & $\int_{-\infty}^{\infty}\frac{(F_{n}(x) - F(x))^2 }{(F(x))}  dx$
      & $-\frac{3n}{2} +2\sum_{i}F(x_{i}) -\frac{1}{n}\sum_{i}((2i-1)ln(F(x_{i})))$ \\
      (ADL) &  &\\
    \hline
      Right-tail AD  & $ad2r=\int_{-\infty}^{\infty}\frac{(F_{n}(x) - F(x))^2 }{(1 - F(x))^{2}}  dx$
      & $ad2r=2\sum_{i}ln(1-F(x_{i})) +\frac{1}{n}\sum_{i} \frac{2i-1}{1-F(x_{n+1-i})}$ \\
      2nd order (AD2R) &  &\\
    \hline
      Left-tail AD  & $ad2l=\int_{-\infty}^{\infty}\frac{(F_{n}(x) - F(x))^2 }{(F(x))^{2}}  dx$
      & $ad2l=2\sum_{i}ln(F(x_{i})) +\frac{1}{n}\sum_{i}\frac{2i-1}{F(x_{i})}$ \\
      2nd order (AD2L) &  &\\
    \hline
    AD 2nd order & $ad2r+ad2l$
      & $ad2r+ad2l$ \\
    (AD2) &  &\\
    \hline
    \end{tabular}
    \label{modifiedAD}
  \end{center}
\end{table}

To fit a distribution by maximum goodness-of-fit estimation, one
needs to fix the argument \code{method}
to \code{"mge"} in the call to \code{fitdist} and to specify the argument \code{gof}
coding for the chosen goodness-of-fit distance. 
% Character string coding for the eight 
% proposed goodness-of-fit distances are given in Table~\ref{MGEdist}.
This function is intended to be used only with continuous non-censored data.
%It may be useful to fit distributions for which maximum likelihood does not provide
%good estimations, such as the uniform distribution (\cite{Luceno06}).


%Below an example of estimation on the \code{danishuni} data set with the three classical 
%goodness-of-fit distances.
%We compare the fitting methods with the distribution function.
%%% R code
%<<danish.mge, echo=TRUE, fig=FALSE>>=
%data(danishuni)
%flndanishAD <- fitdist(danishuni$Loss, "lnorm", method="mge", gof="AD")
%flndanishAD2L <- fitdist(danishuni$Loss, "lnorm", method="mge", gof="AD2L")
%flndanishKS <- fitdist(danishuni$Loss, "lnorm", method="mge", gof="KS")
%flndanishCvM <- fitdist(danishuni$Loss, "lnorm", method="mge", gof="CvM")
%flndanishMLE <- fitdist(danishuni$Loss, "lnorm", method="mle")
%cdfcomp(list(flndanishAD, flndanishAD2L, flndanishKS, flndanishCvM, flndanishMLE), 
%        legend=c("AD", "AD2L", "KS", "CvM", "MLE"), main="Fitting lognormal distribution",
%        xlogscale=TRUE, datapch="*")
%@

%As plotted \ref{fig:danish:mge}, the lognormal distribution is not appropriate to model heavy-tailed datae, but
%this is not the purpose here.
%The second-order Anderson-Darling distance provides the least conservative fit for high quantiles, whereas the
%(classic)  Anderson-Darling distance is the most conservative fit among goodness-of-fit distances.

%\begin{figure}[htb!]
%  \centering
%%% R code
%<<danishmgeplot, echo=FALSE, fig=TRUE, eps=FALSE, width=4, height=4>>=
%cdfcomp(list(flndanishAD, flndanishAD2L, flndanishKS, flndanishCvM, flndanishMLE), 
%        legend=c("AD", "AD2L", "KS", "CvM", "MLE"), main="Fitting lognormal distribution",
%        xlogscale=TRUE, datapch="*")
%@
%\caption{Comparison of statistical distance when fitting lognormal distribution on \code{danishuni}}
%\label{fig:danish:mge}
%\end{figure}

Maximum goodness-of-fit estimation may be useful to give
more weight to data at one tail of the distribution.
Let us go back to the previous example from ecotoxicology.
Instead of trying to find a less classical distribution to correctly
fit the empirical distribution especially on its left tail, one could
consider the fit of the classical lognormal distribution, but minimizing a
goodness-of-fit distance giving more weight to the left tail of the empirical distribution,
so as to correctly estimate the 5$\%$ percentile. 
In the following example of \code{endosulfan} data set, we use left tail 
Anderson-Darling distances of first or second order
(see Figure~\ref{plotfitMGE}).

%%% R code
<<mge.gofcomp.echo, echo=TRUE, fig=FALSE>>=
fendo.ln.ADL <- fitdist(ATV,"lnorm",method="mge",gof="ADL")
fendo.ln.AD2L <- fitdist(ATV,"lnorm",method="mge",gof="AD2L")
cdfcomp(list(fendo.ln, fendo.ln.ADL, fendo.ln.AD2L),
xlogscale = TRUE, main = "",
legendtext = c("MLE",
"Left-tail AD", "Left-tail AD 2nd order"),cex=0.7,
xlegend = "bottomright")
@


\begin{figure}[htb!]
  \centering
  %%% R code
<<mgegofcompplot, echo=FALSE, fig=TRUE, width=6, height=6, eps=FALSE>>=
cdfcomp(list(fendo.ln, fendo.ln.ADL, fendo.ln.AD2L),
xlogscale = TRUE, main = "Fitting a lognormal distribution",
legendtext = c("MLE",
"Left-tail AD", "Left-tail AD 2nd order"),cex=0.7,
xlegend = "bottomright")
@
  \caption{Comparison of a lognormal distribution fitted by MLE
  and by MGE using  two different goodness-of-fit distances : left-tail Anderson-Darling and left-tail Anderson Darling of seond order (example on the \code{endosulfan} data set)}
  \label{plotfitMGE}
\end{figure}

Comparing the $5\%$ percentiles (HC5) calculated using these three fits to the one calculated
from the MLE fit of the Burr distribution, we can observe, on this example,
that fitting the lognormal distribution by maximizing left tail 
Anderson-Darling distances of first or second order
enables to approach the value obtained by fitting the Burr distribution by MLE. 
%%% R code
%<<quantilefitdist, echo=TRUE, fig=FALSE>>=
%(HC5.B.MLE <- quantile(fendo.B,probs = 0.05))
%(HC5.ln.MLE <- quantile(fendo.ln,probs = 0.05))
%(HC5.ln.ADL <- quantile(fendo.ln.ADL,probs = 0.05))
%(HC5.ln.AD2L <- quantile(fendo.ln.AD2L,probs = 0.05))
%@
%%% R code
<<quantilefitdist, echo=TRUE, fig=FALSE>>=
( HC5.estimates <- cbind(empirical = as.numeric(quantile(ATV, probs = 0.05)),
      Burr = as.numeric(quantile(fendo.B,probs = 0.05)$quantiles),
      lognormal_MLE = as.numeric(quantile(fendo.ln,probs = 0.05)$quantiles),
      lognormal_AD2 = as.numeric(quantile(fendo.ln.ADL,probs = 0.05)$quantiles),
      lognormal_AD2L = as.numeric(quantile(fendo.ln.AD2L,probs = 0.05)$quantiles)) )
@

%\subsubsection{Moment matching estimation}
%\label{MME}
%%%%%%%%%%
Another method commonly used to fit parametric distribution is the moment matching estimation (MME). 
It consists in finding the value of the parameter $\theta$  that equalizes the first theoretical 
raw moments of the parametric distribution  to the empirical moments (Equation~\ref{moments})
  \begin{equation}
    \label{moments}
    E(X^{k}|\theta)=\frac{1}{n}\sum_{i=1}^{n}x_{i}^{k} ,
  \end{equation}
for $k=1,\ldots,p$, with $p$ the number of parameters to estimate and
 $x_{i}$ the $n$ observations of variable $X$.
For moments of order greater or equal than 2, it may  also be relevant to match centered moments as
given by Equation (\ref{centmoments}).
  \begin{equation}
    \label{centmoments}
    E\left((X-E(X))^{k}|\theta\right)=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\bar x_n)^{k} 
  \end{equation}
This method can be performed by setting the argument \code{method} to \code{"mme"} in the call to fitdist.
The estimate is computed by a closed-form formula for the following distributions:
normal, lognormal, exponential, Poisson, gamma, logistic, negative binomial,
geometric, beta and uniform distributions (i.e. base \proglang{R} distributions).
In this case, for distributions characterized by one parameter (geometric, Poisson and exponential),
this parameter is simply estimated by matching theoretical and observed means, and for distributions 
characterized by two parameters, these parameters are estimated by matching theoretical and observed 
means and variances (see e.g. \cite{Vose10}).
Otherwise, for not so-common distributions, the equation of moments is solved numerically using 
the \code{optim} function  by minimizing the
sum of squared differences between observed and theoretical moments (see the \pkg{fitdistrplus} reference
manual~\cite{fitdistrplus}
for technical details).

To illustrate this method, we  use a classical data set 
from the Danish insurance industry published in \cite{mcneil97}.
In \pkg{fitdistrplus}, the data set is stored in \code{danishuni} for the univariate version.

\mytodo{mettre deux mots sur les objectifs par rapport a ce type de jeu de donnees pour qu'on comprenne tes choix de lois, 
notamment de la Pareto qui globalement decrit moins bien le jeu de donnees dans sa totalite que la lognormale (cf. un goftstat), mais decrit peut-tre mieux la queue de distribution a droite. 
Dire alors d'emblee qu'on va s'interesser plus a cette queue de distribution a droite et pourquoi}

<<danish.data, echo=TRUE, fig=FALSE>>=
data(danishuni)
str(danishuni)
@
We can first fit a lognormal distribution on \code{danishuni} data set by matching moments using a closed-form formula.
By comparison to the lognormal distribution fitted by maximum likelihood, we observe on the left part of Figure \ref{fig:danish:mme} 
that the moment matching estimation is far more conservative than the maximum likelihood estimation
(overestimate the right tail of the distribution)

\mytodo{pour moi le terme conservative utilise ainsi n'est pas habituel. Est-ce classique
en stat independamment du domaine d'application? Si non il faut le modifier ou l'expliquer mieux. Et je ne suis pas convaincue de comprendre quel ajustement tu preferes au final ici.
Faudrait aussi a mon sens commentez les ajustements}

%%% R code
<<danish.mme, echo=TRUE, fig=FALSE>>=
fdanish.ln.MLE <- fitdist(danishuni$Loss, "lnorm")
fdanish.ln.MME <- fitdist(danishuni$Loss, "lnorm", method="mme", order=1:2)
cdfcomp(list(fdanish.ln.MLE, fdanish.ln.MME), 
        legend=c("lognormal MLE", "lognormal MME"), main="Fitting a lognormal distribution",
        xlogscale=TRUE, datapch="*")
@


In a second time we can fit a Pareto type II distribution.

\mytodo{Explique pourquoi ce choix. Quel interet? Qu'en attends-tu?}

We use the implementation of the \pkg{actuar} package providing moments and limited expected value
for that distribution (in addition to \code{d}, \code{p}, \code{q} and \code{r} functions,
see \cite{actuar12}).
Fitting a heavy-tailed distribution for which the first and the second moments do not exist for
certain values of the shape parameter requires some cautiousness.
This is carried out by providing for the optimization process 
a lower and an upper bound for each parameter.
Our call below immediately calls the L-BFGS-B optimization method in \code{optim}, since this quasi-Newton
allows box constraints\footnote{That is what the B stands for.}.
Note that we have to pass a function for computing the empirical raw moment to \code{fitdist}, 
since the user may choose either (\ref{moments}) and (\ref{centmoments}).

<<danish.mme.pareto, echo=TRUE, fig=FALSE>>=
library(actuar)
fdanish.P.MLE <- fitdist(danishuni$Loss, "pareto",start=c(shape=10, scale=10), 
      optim.method="L-BFGS-B",lower=2+1e-6, upper=Inf)
memp <- function(x, order) ifelse(order == 1, mean(x), sum(x^order)/length(x))
fdanish.P.MME <- fitdist(danishuni$Loss, "pareto", method="mme", order=1:2, 
      memp="memp", start=c(shape=10, scale=10), 
      optim.method="L-BFGS-B",lower=c(2+1e-6,2+1e-6), upper=c(Inf,Inf))
cdfcomp(list(fdanish.P.MLE, fdanish.P.MME), 
        legend=c("Pareto MLE", "Pareto MME"), main="Fitting a Pareto distribution",
        xlogscale=TRUE, datapch="*")
@

\setkeys{Gin}{width=0.8\textwidth} %default

\begin{figure}[htb!]
  \centering
  %%% R code
<<danishmmeplot, echo=FALSE, fig=TRUE, width=7, height=3.5, eps=FALSE>>=
par(mfrow=c(1, 2))
cdfcomp(list(fdanish.ln.MLE, fdanish.ln.MME), 
        legend=c("lognormal MLE", "lognormal MME"), main="Fitting a lognormal distribution",
        xlogscale=TRUE, datapch="*")
cdfcomp(list(fdanish.P.MLE, fdanish.P.MME), 
        legend=c("Pareto MLE", "Pareto MME"), main="Fitting a Pareto distribution",
        xlogscale=TRUE, datapch="*")
@
\caption{Comparison between MME and MLE when fitting a lognormal or a Pareto distribution to loss data from the \code{danishuni} data set}
\label{fig:danish:mme}
\end{figure}


% Je ne vois pas l'interet de comparer les moments. 
% S'ils n'etaient pas egaux cela voudrait dire que le methode ne marche pas
% pas que l'ajustement est mauvais
% c'est pouruqoi je propose de remplacer par une figure a cote de l'autre
% et un commentaire a ajouter
% c(theo = mpareto(1, fparedanishMME$estimate[1], fparedanishMME$estimate[2]),
% emp = memp(danishuni$Loss, 1))  
% c(theo = mpareto(2, fparedanishMME$estimate[1], fparedanishMME$estimate[2]),
% emp = memp(danishuni$Loss, 2))

\mytodo{Faudrait peut-etre conclure sur l'interet de la methode des moments. Ou 
au contraire une remarque de prudence par rapport a cette methode qui est parfois 
la seule utilisee dans certains logiciels. Enfin il faut conclure quelque chose
en tout cas. Voici un essai ci-dessous mais tu as certainement d'autres choses a dire
et/ou un autre point de vue}

We can see on Figure \ref{fig:danish:mme} that matching moments and maximum likelihood fits
are far less distant for the Pareto distribution than for the lognormal distribution on 
this data set. Maximum likelihood and moment matching are certainly the most commonly used method for fitting distributions. But one should keep in mind that these two methods may give very different results. When choosing the matching moment method, the user should be aware 
of its great sensitivity to outliers. This may be seen as an advantage in our example if the
objective is to better describe the right tail of the distribution, but it may be seen as a
drawback if the objective is different.

  

%\subsubsection{Quantile matching estimation}
%\label{QME}
%%%%%%%%%%
Fitting of a parametric distribution may also be done by matching theoretical quantiles
of the parametric distributions (for specified probabilities) against the empirical quantiles.
Equation (\ref{quantiles}) below is thus very similar to Equations (\ref{moments}) and (\ref{centmoments})
  \begin{equation}
    \label{quantiles}
    F^{-1}(p^{k}|\theta)=Q_{n,p_{k}} 
  \end{equation}
for $k=1,\ldots,p$, with $p$ the number of parameters to estimate (dimension of $\theta$ if there is
no fixed parameters) and
 $Q_{n,p_{k}}$ the empirical quantiles calculated from data for specified probabilities $p_{k}$.

Quantile matching is performed by setting the argument \code{method}
to \code{"qme"} in the call to \code{fitdist} and adding an argument \code{probs}
defining the probabilities for which the quantile matching is performed.
The length of this vector must be equal
to the number of parameters to estimate. Empirical quantiles are computed using the
\code{quantile} function of the \pkg{stats} package using the \texttt{type} 
argument  equal to 7 by default, but the type of quantile
can be easily changed by using the \texttt{qty} argument in the call to the \texttt{qme} function.   
The quantile matching is carried out numerically, 
by minimizing the
sum of squared differences between observed and theoretical quantiles.
%%% R code
<<danish.qme.echo, echo=TRUE, fig=FALSE>>=
fdanish.ln.QME1 <- fitdist(danishuni$Loss, "lnorm", method="qme", probs=c(1/3, 2/3))
fdanish.ln.QME2 <- fitdist(danishuni$Loss, "lnorm", method="qme", probs=c(3/4, 4/5))
cdfcomp(list(fdanish.ln.MLE, fdanish.ln.QME1, fdanish.ln.QME2), 
        legend=c("MLE", "QME(1/3, 2/3)", "QME(3/4, 4/5)"), main="Fitting a lognormal distribution",
        xlogscale=TRUE, datapch="*")
@
Above is an example of fitting of a lognormal distribution to \code{danishuni} data set 
by matching probabilities $(p_1= 1/3, p_2=2/3)$ and $(p_1= 3/4, p_2=4/5)$.
As expected, the second QME fit is more conservative when looking at the tail of the distributions.
Compared to the maximum likelihood estimation, the second QME fit is also more conservative, whereas
the first QME fit is less conservative.
The quantile matching estimation is of particular interest when we need a focus 
around particular quantiles, e.g. $p=99.5\%$ in the Solvency II insurance context or
$p=5\%$ for the HC5 estimation in the ecotoxicology context.



\setkeys{Gin}{width=0.5\textwidth} %default


\begin{figure}[htb!]
  \centering
  %%% R code
<<danishqmeplot, echo=FALSE, fig=TRUE, width=4, height=4, eps=FALSE>>=
cdfcomp(list(fdanish.ln.MLE, fdanish.ln.QME1, fdanish.ln.QME2), 
        legend=c("MLE", "QME(1/3, 2/3)", "QME(3/4, 4/5)"), main="Fitting a lognormal distribution",
        xlogscale=TRUE, datapch="*")
@
\caption{Comparison between QME and MLE when fitting a lognormal distribution to loss data from the \code{danishuni} data set}
\label{fig:danish:qme}
\end{figure}




\subsection{Customization of the optimization algorithm}
\label{Customization}
%%%%%%%%%%
Each time a numerical minimization (or maximization) is carried out using \code{fitdist}, 
the \code{optim} function of the \pkg{stats} package  is used by default with the 
\code{"Nelder-Mead"} method for distributions characterized by more than one parameter and
the \code{"BFGS"} method for distributions characterized by only one parameter.
Sometimes the default algorithm fails to converge. It is then
interesting to change some options of the \code{optim} function or to use another optimization
function than \code{optim} to maximize the likelihood or to minimize a squared difference.
The argument \code{optim.method} can be used in the call to \code{fitdist} or
\code{fitdistcens}. It will internally be passed to \code{mledist} and to \code{optim}
(see the help page of \code{optim} from the package \pkg{stats} for details about the different
algorithms available proposed by \code{optim}).

%This argument may be fixed to \code{"Nelder-Mead"} (the robust derivative-free Nelder and Mead method), 
%\code{"BFGS"} (the BFGS quasi-Newton method), \code{"CG"} (the conjugate gradient hessian-free method), 
%\code{"SANN"} (a variant of (stochastic) simulated annealing) or \code{"L-BFGS-B"} (a modification of the BFGS 
%quasi-Newton method which enables box constraints optimization and limited-memory usage). 
%For the use of the last method the 
%arguments \code{lower} and/or \code{upper} also have to be passed. 
%More details on these optimization
%functions may be found in the help page of \code{optim} from the package \pkg{stats}.


Below are examples of fits of a gamma distribution $\mathcal{G}(\alpha, \lambda)$ to 
the \code{groundbeef} data set with various algorithms. Note that the conjugate gradient algorithm
(\code{"CG"}) needs far more 
iterations to converge (around 2500 iterations)
compared to other algorithms (converging in less than 100 iterations).
%%% R code
<<optimmethod.gamma, echo=TRUE>>=
data(groundbeef)
fNM <- fitdist(groundbeef$serving, "gamma", optim.method="Nelder-Mead")
fBFGS <- fitdist(groundbeef$serving, "gamma", optim.method="BFGS") 
fSANN <- fitdist(groundbeef$serving, "gamma", optim.method="SANN")
fCG <- try(fitdist(groundbeef$serving, "gamma", optim.method="CG", control=list(maxit=10000)))
if(class(fCG) == "try-error")
  fCG <- list(estimate=NA)
@


It is also possible to use another function than \code{optim} to maximize the likelihood.
This optimization function must be specified by the argument \code{custom.optim} 
in the call to \code{fitdist}. But before that, it may be necessary to customize this optimization function to meet
the following requirements. (1) \code{custom.optim} function must have (at least) the following arguments:
\code{fn} for the function to be optimized and \code{par} for the initialized parameters. 
(2) \code{custom.optim} should carry out a MINIMIZATION and must return
(at least) the following components: \code{par} for the estimate, \code{convergence} for the convergence
code, \code{value} for \code{fn(par)} and \code{hessian}.
Below is an example of code written to wrap the \code{genoud} function from the \pkg{rgenoud} package in
order to respect our optimization ``template''.
The \pkg{rgenoud} package implements the genetic (stochastic) algorithm.
%%% R code
<<optimmethod.customgenoud, echo=TRUE>>=
mygenoud <- function(fn, par, ...) 
{
   require(rgenoud)
   res <- genoud(fn, starting.values=par, ...)        
   standardres <- c(res, convergence=0)
   return(standardres)
}
@

The customized optimization function can then be passed as the argument \code{custom.optim} 
in the call to \code{fitdist}
or \code{fitdistcens}. The following code can for example be used to fit a gamma distribution to the
\code{groundbeef} data set. Note that in this example various arguments are also passed from \code{fitdist} 
to \code{genoud} :
\code{nvars}, \code{Domains}, \code{boundary.enforcement}, 
\code{print.level} and \code{hessian}.
The code below compares all the parameter estimates by the different algorithms:
shape and rate parameters are relatively similar on this example.
%%% R code
<<optimmethod.customgenoud.fitdist, echo=TRUE, eval=TRUE>>=
fgenoud <- mledist(groundbeef$serving, "gamma", custom.optim= mygenoud, nvars=2, 
    max.generations=10, Domains=cbind(c(0,0), c(10,10)), boundary.enforcement=1, 
    hessian=TRUE, print.level=0, P9=10)
cbind(NM = fNM$estimate,
BFGS = fBFGS$estimate,
SANN = fSANN$estimate,
CG = fCG$estimate,
fgenoud = fgenoud$estimate)
@

% redondant avec ce qui est ecrit precedemment
%On the \code{groundbeef} data set, we observe that algorithms provide reasonably the same value of
%parameter estimate $\hat\theta=(\hat\alpha, \hat\lambda)$.


\subsection{Fitting distributions to other types of data}
\label{otherdata}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Analytical methods often lead to semi-quantitative results which are referred to as
censored data. Observations only known to be under a limit of detection are called
left censored data. Observations only known to be above a limit of quantification
are called right censored data. Results known to lie between two bounds are called
interval censored data. These two bounds may correspond to a limit of detection and 
a limit of quantification, or more generally to uncertainty bounds around the observation.
Right censored data are also commonly encountered among survival data.
A data set may thus contain right, left, or interval censored data, or may be a mixture
of these categories, possibly with different upper and lower bounds.
Censored data are sometimes excluded from the data analysis or replaced by a fixed value, which
in both cases may lead to biased results. A more recommended approach to correctly model
such data is based upon maximum likelihood \cite{kleinmoeschberger03,helsel05}. 
We chose this approach in our package.

Censored data can thus contain left censored, right censored and interval censored values, 
with several lower and upper bounds. Before using the \pkg{fitdistrplus} package,
such data must be coded into a dataframe with two columns,
 respectively named \code{left} 
 and \code{right}, describing each observed value as an interval.
 The \code{left} column contains either \code{NA} for left censored observations,
 the left bound of the interval for interval censored observations,
 or the observed value for non-censored observations.
 The \code{right} column contains either \code{NA} for right censored observations,
 the right bound of the interval for interval censored observations,
 or the observed value for non-censored observations.
To illustrate the use of package \pkg{fitdistrplus} to fit distributions
to censored continous data, we  use another
data set from ecotoxicology, included in our package and named  \code{salinity}. 
This data set contains acute salinity tolerance (LC50 values in electrical conductivity, $mS$.$cm^{-1}$)
of riverine macro-invertebrates taxa from the southern Murray-Darling Basin in 
Central Victoria, Australia
(see \cite{kefford07}). 

%The \code{smokedfish} data set, included in the package,
%corresponds to the observation of a continuous censored variable, 
%the \emph{Listeria monocytogenes} microbial concentration, on a random
%sample of smoked fish distributed on the Belgian market in the period
%2005 to 2007 (\cite{Busschaert10}).
%Censored data are coded within 2 columns named left and right, describing
%each observed value of \emph{Listeria monocytogenes} concentration 
%(in $CFU.g^{-1}$) as an interval. 
%The left column contains either \code{NA} for
%left censored observations, the left bound of the interval for interval censored
%observations, or the observed value for non-censored observations. The right
%column contains either \code{NA} for right censored observations, the right bound of
%the interval for interval censored observations, or the observed value for noncensored
%observations.
%%% R code
%<<datsmokedfish, echo=TRUE>>=
%data(smokedfish)
%str(smokedfish)
%@

%%% R code
<<datsalinity, echo=TRUE>>=
data(salinity)
str(salinity)
@
     
%\subsubsection{Graphical display of the observed distribution}
%\label{censored:graph}
%%%%%%%%%%

Using censored data such as those coded in the \code{salinity} data set,
the empirical distribution can be plotted using the \code{plotdistcens} function.
By default, this function uses the Expectation-Maximization approach of Turnbull \cite{Turnbull74} to compute the overall
empirical cdf curve with optional confidence intervals, by calls to \code{survfit}
and \code{plot.survfit} functions from the \pkg{survival} package 
(Figure~\ref{cdfcompcens} shows the Turnbull plot of data together with two fitted distributions). 
A less rigorous
but sometimes more illustrative plot to see the real nature of censored data can be 
obtained by fixing the argument \code{Turnbull} to \code{FALSE} in the call to \code{plotdistcens}
(see Figure~\ref{plotdistcens} for an example and the help page of Function
\code{plotdistcens} for details).

%%% R code
%<<plotsalinity.echo, echo=TRUE, fig=FALSE>>=
%plotdistcens(salinity)
%@



%%% R code
<<plotsalinity2.echo, echo=TRUE, fig=FALSE>>=
plotdistcens(salinity,Turnbull = FALSE)
@

% ------------------ previous method -----------------------------
%Data are reported directly as segments for interval, left and right censored data, 
%and as points for non-censored data. Before plotting, observations are ordered and a rank r
%is associated to each of them. Left censored observations are ordered
%first, by their right bounds. Interval censored and non censored observations
%are then ordered by their mid-points and, at last, right censored observations are
%ordered by their left bounds. If argument \texttt{leftNA} (resp. \texttt{rightNA}) is finite,
%left censored (resp. right censored) observations are considered as interval censored
%observations and ordered by mid-points with non-censored and interval censored data.
%It is sometimes necessary to fix \texttt{leftNA} or \texttt{rightNA} to a realistic 
%extreme value, even if not exactly known, to obtain a reasonable global ranking of 
%observations. After ranking, each of the n observations is plotted as a point (one x-value) 
%or a segment (an interval of possible x-values),
%with an y-value equal to r/n, r being the rank of each observation in the global ordering
%previously described.




\setkeys{Gin}{width=0.5\textwidth} %default

\begin{figure}[htb!]
  \centering
  %%% R code
<<plotsalinity, echo=FALSE, fig=TRUE, width=4, height=4, eps=FALSE, result=hide>>=
plotdistcens(salinity,Turnbull = FALSE)
@
  \caption{Simple plot of censored data (72-hour acute salinity tolerance of riverine macro-invertebrates from 
   the \code{salinity} data set) as ordered points 
   and intervals}
  \label{plotdistcens}
\end{figure}




%\subsubsection{Maximum likelihood estimation}
%\label{censored:MLE}
%%%%%%%%%%

As for non censored data, one or more parametric distributions can
be fitted to the censored data set, one at a time, but using in this case
the \code{fitdistcens} function. This function estimates the vector of distribution parameters $\theta$
by maximizing the likelihood for censored data defined as:
  \begin{equation}
    \label{likelihoodC}
    L(\theta)=\prod_{i=1}^{N_{nonC}} f(x_{i}|\theta)
    \times \prod_{j=1}^{N_{leftC}} F(x^{upper}_{j}|\theta)
    \times \prod_{k=1}^{N_{rightC}} (1- F(x^{lower}_{k}|\theta))
    \times \prod_{m=1}^{N_{intC}} (F(x^{upper}_{m}|\theta)- F(x^{lower}_{j}|\theta))
  \end{equation}
with $x_{i}$ the $N_{nonC}$ non-censored observations,
$x^{upper}_{j}$ upper values defining the $N_{leftC}$ left-censored observations,
$x^{lower}_{k}$ lower values defining the $N_{rightC}$ right-censored observations,
$[x^{lower}_{m} ; x^{upper}_{m}]$ the intervals defining the $N_{intC}$ interval-censored observations,
and F the cumulative distribution function of the parametric distribution.

As \code{fitdist}, \code{fitdistcens} returns the results of the fit of any parametric distribution
to a data set as an S3 class object that can be easily printed,
summarized or plotted.
For the \code{salinity} data set, a lognormal distribution or a loglogistic can be fitted 
as commonly done in ecotoxicology for such data. 
As with \code{fitdist}, for some distributions (see \cite{fitdistrplus} for details), 
it is necessary to specify initial 
values for the distribution parameters in the argument \code{start}.
The \code{plotdistcens} function can help to find correct initial values for 
the distribution parameters in non trivial cases, by an manual iterative use if necessary.
%%% R code
<<fitsalinity.echo, echo=TRUE, fig=FALSE>>=
fsal.ln <- fitdistcens(salinity, "lnorm")
fsal.ll <- fitdistcens(salinity, "llogis", start=list(shape=5, scale=40))
summary(fsal.ln)
summary(fsal.ll)
@

Computations of goodness-of-fit statistics have not yet been 
developed for fits using censored data but the quality of fit 
can be judged using Akaike and Schwarz information criteria (AIC and BIC) and the goodness-of-fit CDF plot, 
respectively provided when summarizing or plotting an object of class \code{"fitdistcens"}. 
Function \code{cdfcompcens} can also be used to compare the fit of various
distributions to the same censored data set. Its call is similar to the one of \code{cdfcomp}. Below is
an example of comparison of the two fitted distributions to the \code{salinity} data set (see Figure~\ref{cdfcompcens}).

%%% R code
<<fitsalinity.cdfcomp.echo, echo=TRUE, fig=FALSE, eval=FALSE>>=
cdfcompcens(list(fsal.ln, fsal.ll),
    legendtext=c("lognormal", "loglogistic "))
@


\setkeys{Gin}{width=0.5\textwidth} %default
\begin{figure}[htb!]
  \centering
  %%% R code
<<fitsalinitycdfcompplot, echo=FALSE, fig=TRUE, width=4, height=4, eps=FALSE>>=
cdfcompcens(list(fsal.ln, fsal.ll),
    legendtext=c("lognormal", "loglogistic "))
@
  \caption{Goodness-of-fit CDF plot for fits of a lognormal and a loglogistic distribution
  to censored data: LC50 values from 
   the \code{salinity} data set}
  \label{cdfcompcens}
\end{figure}

Function \code{bootdistcens} is the equivalent of \code{bootdist} for censored data, except that it 
only proposes nonparametric bootstrap, as it is not obvious to simulate censoring within a parametric 
bootstrap resampling procedure. The generic function \code{quantile} can also be applied, as for 
continuous non-censored data,
to an object of class \code{"fitdistcens"} or \code{"bootdistcens"}.

%<<echo=TRUE, fig=FALSE>>=
%plot(flog10C)
%@
%\begin{figure}[htb]
%  \centering
%<<echo=FALSE, results=hide, fig=TRUE>>=
%plot(flog10C)
%@
%  \caption{Goodness-of-fit CDF plot for a fit of a continuous distribution
%  on censored data (a lognormal distribution fitted to microbial counts from 
%   the ``smoked fish'' data set)}
%  \label{plotfitdistcens}
%\end{figure}


In addition to the fit of distributions to censored or non censored continuous data, our package
can also accomodate discrete variables, such as count numbers, using the functions 
developped for continuous non-censored data. 
%Specific distributions such as 
%the Poisson distribution or the negative binomial distribution can be fitted with the same functions
%used for continuous non-censored data. 
These functions will provide somewhat different graphs
and statistics, taking into account the discrete type of the modeled variable.
The discrete nature of the variable is automatically recognized when a classical distribution is fitted to data
(binomial, negative binomial, geometric, hypergeometric and Poisson distributions) but must 
be indicated by fixing argument \code{discrete} to \code{TRUE} in the call to functions in other cases.
The \code{toxocara} data set included in the package corresponds to the observation of such a discrete variable. 
It reports numbers of \emph{Toxocara cati} parasites present in digestive tract,
from a random sampling of feral cats living on Kerguelen island (\cite{Fromont01}). We  use it 
to illustrate the case of discrete data.
%%% R code
<<dattoxocara, echo=TRUE>>=
data(toxocara)
str(toxocara)
@

%In some cases a discrete variable may be plotted as a continuous one, for example for a large data set
%from a binomial distribution converging to a normal one, but
%The \code{plotdist} function also proposes specific plots in density and in cdf
%for discrete variables (Figure~\ref{plotdistdisc}):
%%% R code
%<<figtoxocara.echo, echo=TRUE, fig=FALSE, eval=FALSE>>=
%plotdist(toxocara$number, discrete = TRUE)
%@
%\begin{figure}[htb!]
%  \centering
  %%% R code
%<<figtoxocaraplot, echo=FALSE, fig=TRUE, width=12, height=6, eps=FALSE>>=
%plotdist(toxocara$number, discrete = TRUE)
%@
%  \caption{Density and cdf plots of an empirical distribution for a discrete variable
%  (number of \emph{Toxocara cati} parasites from the \code{toxocara} data set)}
%  \label{plotdistdisc}
%\end{figure}

% FAUT-IL LE METTRE ???????????????????????
%As for continuous non-censored data (see Section~\ref{fitnoncenscont})
%the \code{descdist} function can be used, but with the argument \code{discrete}
%fixed to \code{TRUE}. This function will especially 
%compute skewness and kurtosis values, and plot them in a skewness-kurtosis plot 
% with skewness and kurtosis values or set of values of 
%Poisson and negative binomial
%(Figure~\ref{Cullenplotdisc}), 
%together with values for the
%normal distribution, to which discrete distributions may converge. 

%Looking at the skewness-kurtosis plot (Figure~\ref{Cullenplotdisc}) obtained
%for the number of \emph{Toxocara cati} parasites from 
%the ``Toxacara'' data set, one could try the fit of Poisson and negative-binomial %distributions.

%<<echo=TRUE, fig=FALSE>>=
%descdist(toxocara$number,discrete = TRUE,boot=1000)
%@
%\begin{figure}[htb]
%  \centering
%<<echo=FALSE, results=hide, fig=TRUE>>=
%descdist(toxocara$number,discrete = TRUE,boot=1000)
%@
%  \caption{Skewness-kurtosis plot for a discrete variable
%  (number of \emph{Toxocara cati} parasites from the ``Toxocara'' data set)}
%  \label{Cullenplotdisc}
%\end{figure}


The fit of a discrete distribution to discrete data by maximum
likelihood estimation requires the same procedure as for continuous non-censored data. 
As an example, 
using the \code{toxocara} data set, Poisson and
negative distributions can be easily fitted.
%%% R code
<<fittoxocara.poisnbinom, echo = TRUE, fig = FALSE>>=
(ftoxo.P <- fitdist(toxocara$number, "pois"))
(ftoxo.nb <- fitdist(toxocara$number, "nbinom"))
@

For discrete distributions, the plot of an object of class \code{"fitdist"} simply provides
two goodness-of-fit plots comparing empirical and theoretical distributions
in pdf and in cd f(Figure~\ref{plotdiscfitP}). Function \code{cdfcomp} can also be used to compare several plots
to the same data set, as follows for the previous fits (Figure~\ref{plotdiscfit}). 
<<fittoxocara.pois.echo, echo=TRUE, fig=FALSE>>=
plot(ftoxo.P)
@

\setkeys{Gin}{width=0.8\textwidth} %default

\begin{figure}[htb]
  \centering
<<fittoxocarapois, echo=FALSE, results=hide, fig=TRUE, width=10, height=5, eps=FALSE>>=
plot(ftoxo.P)
@
  \caption{Plot of the fit of a discrete distribution (Poisson distribution
  fitted to numbers of \emph{Toxocara cati} parasites from the \code{toxocara} data set)}
  \label{plotdiscfitP}
\end{figure}


<<fittoxocara.poisnbinom.echo, echo=TRUE, fig=FALSE>>=
cdfcomp(list(ftoxo.P,ftoxo.nb),legendtext=c("Poisson", "negative binomial"))
@

\setkeys{Gin}{width=0.5\textwidth} %default

\begin{figure}[htb]
  \centering
<<fittoxocarapoisnbinomplot, echo=FALSE, results=hide, fig=TRUE, width=4, height=4, eps=FALSE>>=
cdfcomp(list(ftoxo.P,ftoxo.nb),legendtext=c("Poisson", "negative binomial"))
@
  \caption{Comparison of the fits of a negative binomial and a Poisson distribution
   to numbers of \emph{Toxocara cati} parasites from the \code{toxocara} data set)}
  \label{plotdiscfit}
\end{figure}


When fitting discrete distributions, the Chi-squared statistic is computed by 
the \code{gofstat} function using cells defined 
by the argument \code{chisqbreaks} or cells automatically defined from the data in order 
to reach roughly the same number of observations per cell, roughly equal to the argument
\code{meancount}, or sligthly more if there are some ties. 
The choice to define cells from the empirical distribution (data), and not from the
theoretical distribution, was done to enable the comparison of Chi-squared values obtained
with different distributions fitted on a same data set.
If arguments \code{chisqbreaks} and \code{meancount} 
are both omitted, \code{meancount} is fixed in order to obtain roughly $(4n)^{2/5}$ cells, 
with $n$ the length of the data set~\cite{Vose10}. Using this default option with 
the fits of the Poisson and the negative binomial distribution to \code{toxocara} data set 
are compared as follows, 
giving the preference
to the negative binomial distribution, from both Chi-squared statistics and information criteria:
%%% R code
<<fittoxocara.poisnbinom.gof, echo=TRUE, fig=FALSE>>=
gofstat(list(ftoxo.P,ftoxo.nb))
@

%Among its returned values, Function \code{gofstat} provides a table with observed and theoretical 
%counts used for the Chi-squared calculations:
%%% R code
%<<fittoxocara.poisnbinom.gof.chisq, echo=TRUE,fig=FALSE>>=
%gofstat(fnb)$chisqtable
%@



\section{Conclusion}
\label{ccl}
%%%%%%%%%%

In this paper, we present the \proglang{R} statistical package \pkg{fitdistrplus} for distribution fitting and demonstrate its use and usefulness. 
This package is already used a lot by practionners and academics for simple MLE fits in \cite{distrModJSS,jaloustreetal11,saketal11,wilson12,kochetal12,marquetouxetal12,nordan12,
scholletal12,suuronenetal12,varoetal12,mandletal13}, for MLE fits and goodness-of-fit statistics in \cite{garcia12,tarnczi11,bagariaetal12,benavidesetal12,breitbach12,poduje12,pouillotetal10}, for MLE fits and bootstrap in  \cite{croucheretal12,meheustetal12,orellanoetal12,telloetal12,hoelzeretal12}, for MLE fits, bootstrap and goodness-of-fit statistics in \cite{rebuge12}, for MME fit in \cite{luangkesornetal12}, for censored MLE and bootstrap in \cite{lehaetal11,poulliotetal12,jongenburgeretal12,commeauetal12,pouillotetal11}, for graphic analysing in \cite{anandetal12,rosa12}, for grouped-data fitting methods in  \cite{fusteinercostafreda12} and more generally in  \cite{eling12,busschaertetal10,brooksetal11,aktassjostrand11,eikhermann12,bakos11}.
Many extensions of this package are planned in the future: multivariate distribution fitting, extensions of advanced fitting methods for censored data, possibility to specify new types of moments (e.g. limited expected values) for MME.
In future versions of our package, we plan to implement other estimation methods for censored-data, support of truncated data, and  multivariate distribution fitting.


\bibliographystyle{plain}
\bibliography{fitdistrplus,paperscitingfitdistrplus}


 
\end{document}
