---
title: Fitting distributions by MLE to non-censored data
author: Marie Laure Delignette Muller, Christophe Dutang
date: '`r Sys.Date()`'
output:
  pdf_document:
    number_sections: true
    toc: true
vignette: |
  %\VignetteIndexEntry{Fitting distributions by MLE to non-censored data} 
  %\VignetteEngine{knitr::rmarkdown} 
  %!\VignetteEncoding{UTF-8}
  \usepackage[utf8]{inputenc}
bibliography: jssfitdistrplus.bib    
header-includes:
- \usepackage{url}
- \newcommand{\ind}{1\!\!1}
- \newcommand{\R}{\mathbb R}
- \newcommand{\N}{\mathbb N}
- \newcommand{\calD}{\mathcal D}
- \newcommand{\calL}{\mathcal L}
- \newcommand{\systL}{\left\{\begin{array}{ll}}
- \newcommand{\systR}{\end{array}\right.}
- \newcommand{\matL}{\left(\begin{matrix}}
- \newcommand{\matR}{\end{matrix}\right)}
- \newcommand{\detL}{\left|\begin{matrix}}
- \newcommand{\detR}{\end{matrix}\right|}
- \newcommand{\pkg}{\textbf}
- \newcommand{\proglang}{\textsf}
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
require(fitdistrplus)
library("knitcitations")
cleanbib()
options("citation_format" = "pandoc")
bib <- read.bibtex("jssfitdistrplus.bib")
```


# Choice of candidate distributions

For illustrating the use of various functions of the \pkg{fitdistrplus} package 
with continuous non-censored data, we will  first use
a data set named `groundbeef` which is included in our package.
This data set contains pointwise values of
serving sizes in grams, collected in a French survey, for ground beef patties consumed by 
children under 5 years old. It was used in a quantitative risk assessment 
published by `r citep(bib['Delignette08'])`.
```{r datgroundbeef, echo=TRUE, warning=FALSE}
set.seed(1234)
library("fitdistrplus")
data("groundbeef")
str(groundbeef)
```


Before fitting one or more distributions to a data set, it is generally
necessary to choose good candidates among a predefined set of distributions.
This choice may be guided by the knowledge of stochastic processes governing
the modelled variable, or, in the absence of knowledge regarding the underlying process, 
by the observation of its empirical distribution.
To help the user in this choice, we developed functions to plot and
characterize the empirical distribution.

First of all, it is common to start with plots of the empirical distribution 
function and the histogram (or density plot), which can be obtained with the `plotdist` function of the \pkg{fitdistrplus} package.
This function provides two plots (see Figure~\ref{plotdistcont}): the left-hand plot is by default the histogram 
on a density scale
(or density plot of both, according to values of arguments `histo` and `demp`)
and the right-hand  plot the empirical cumulative distribution function (CDF).
```{r figgroundbeefplot, echo=TRUE, fig.height=3, fig.width=6, warning=FALSE}
plotdist(groundbeef$serving, histo = TRUE, demp = TRUE)
```





In addition to empirical plots, descriptive statistics may help to choose candidates to describe a distribution
among a set of parametric distributions. Especially the skewness and kurtosis, linked to the third and fourth moments, 
are useful for this purpose. A non-zero skewness reveals a lack of symmetry of the empirical distribution,
while the kurtosis value quantifies the weight of tails in comparison to the normal distribution for which
the kurtosis equals 3.
The skewness and kurtosis and their corresponding unbiased estimator `r citep(bib['casellaberger02'])` from a sample 
$(X_i)_i \stackrel{\text{i.i.d.}}{\sim} X$ with observations $(x_i)_i$ are given by
  \begin{equation}
    \label{skewness}
    sk(X) = \frac{E[(X-E(X))^3]}{Var(X)^{\frac{3}{2}}}~,~
    \widehat{sk}=\frac{\sqrt{n(n-1)}}{n-2}\times\frac{m_{3}}{m_{2}^{\frac{3}{2}}},
  \end{equation}

  \begin{equation}
    \label{kurtosis}
    kr(X) = \frac{E[(X-E(X))^4]}{Var(X)^{2}}~,~
    \widehat{kr}=\frac{n-1}{(n-2)(n-3)}((n+1) \times \frac{m_{4}}{m_{2}^{2}}-3(n-1)) + 3,
  \end{equation}
where $m_{2}$, $m_{3}$, $m_{4}$ denote empirical moments defined by
$m_{k}=\frac{1}{n}\sum_{i=1}^n(x_{i}-\overline{x})^{k}$, with
$x_{i}$ the $n$ observations of variable $x$ and $\overline{x}$ their mean value.

The  `descdist` function provides classical descriptive statistics
(minimum, maximum, median, mean, standard deviation), skewness and kurtosis. By default, 
unbiased estimations of the three last statistics are provided. Nevertheless,
the argument `method`
can be changed from `"unbiased"` (default) to `"sample"` to obtain  
them without correction for bias. 
A skewness-kurtosis plot such as the one proposed by `r citep(bib['Cullen99'])` is  provided by 
the `descdist` function for the empirical distribution 
(see Figure~\ref{Cullenplotcont} for the `groundbeef` data set). 
On this plot, values for common distributions are displayed in order 
to help the choice of distributions to fit to data. For some distributions (normal, uniform,
logistic, exponential), there is only one possible value for the skewness and the kurtosis.
 Thus, the distribution is represented by a single point on the plot. For other distributions, 
areas of possible values are represented, consisting in lines (as for gamma and lognormal distributions), 
or larger areas (as for beta distribution).
    
Skewness and kurtosis are known not to be robust. In order to take into account the uncertainty 
of the estimated values of kurtosis and skewness from data, a nonparametric bootstrap 
procedure `r citep(bib['efrontibshirani94'])` can be performed by using the argument `boot`. %to an integer above 10.
Values of skewness and kurtosis are computed on bootstrap samples (constructed by 
random sampling with replacement from the original data set) and reported on the 
skewness-kurtosis plot. 
Nevertheless, the user needs to know that skewness and kurtosis,  like all higher moments, have a very high variance. This is a problem which cannot be completely solved by the use of bootstrap. The skewness-kurtosis plot should then be regarded as indicative only.
The properties of the random variable should be considered, notably its expected value and its range,
as a complement to the use of the `plotdist` and `descdist` functions. 
Below is a call to the `descdist` function to describe the distribution 
of the serving size from the `groundbeef` data set and to draw the corresponding skewness-kurtosis
plot (see Figure~\ref{Cullenplotcont}). Looking at the results on this example
with a positive skewness and a kurtosis not far from 3,
the fit of three common right-skewed distributions could be considered, Weibull, gamma and 
lognormal distributions.
```{r descgroundbeefplot, fig.height=5, fig.width=5, echo=TRUE}
descdist(groundbeef$serving, boot = 1000)
```





# Fit of distributions by MLE


Once selected, one or more parametric distributions $f(.\vert \theta)$ 
(with parameter $\theta\in\mathbb{R}^d$) may be fitted to the data set, 
one at a time, using the `fitdist` function. 
Under the i.i.d. sample assumption, distribution parameters $\theta$ are by default estimated by maximizing the
likelihood function defined as:
  \begin{equation}
    \label{likelihood}
    L(\theta)=\prod_{i=1}^n f(x_{i}\vert \theta)
  \end{equation}
with $x_{i}$ the $n$ observations of variable $X$ and $f(.\vert \theta)$ the density function of the 
parametric distribution.
The other proposed estimation methods are described in Section~\ref{Alternatives}. 


The fit of a distribution using `fitdist` assumes that the corresponding 
`d`, `p`, `q` functions (standing respectively for the density, 
the distribution and the quantile functions) are defined.
Classical distributions are already defined in that way in the \pkg{stats} package,
e.g., `dnorm`, `pnorm` and `qnorm` for the normal distribution
(see `?Distributions`). Others
may be found in various packages (see the CRAN task view: Probability Distributions at \url{http://cran.r-project.org/web/views/Distributions.html}). 
Distributions not found in any package must be implemented by the user as
`d`, `p`, `q` functions.
In the call to `fitdist`, a distribution  has to be specified via
the argument `dist` either by the character string corresponding to its common root name
used in the names of `d`, `p`, `q` functions
(e.g., `"norm"` for the normal distribution) 
or by the density function itself, from which
the root name is extracted (e.g., `dnorm` for the normal distribution).
Numerical results returned by the `fitdist` function are 
(1) the parameter estimates, (2) the estimated standard errors (computed from the estimate
of the Hessian matrix at the maximum likelihood solution), (3) the loglikelihood, 
(4) Akaike and Bayesian information criteria (the so-called AIC and BIC), and (5) the correlation matrix
between parameter estimates.
Below is a call to the `fitdist` function to fit a Weibull distribution 
to the serving size from the `groundbeef` data set.
```{r fitgroundbeef.weibull, echo=TRUE}
fw <- fitdist(groundbeef$serving, "weibull")
fw
```

# Generic functions for a `"fitdist"` object
The `fitdist` function returns an S3 object of class `"fitdist"` 
for which `print`, `summary` and `plot` functions are provided.
```{r fitgroundbeef.generic, echo=TRUE}
print(fw)
summary(fw)
```

The plot of an object of class `"fitdist"` provides 
four classical goodness-of-fit plots `r citep(bib['Cullen99'])`
presented on Figure~\ref{groundbeef:comp}: 
\begin{itemize}
\item a density plot representing the density function of the fitted distribution 
along with the histogram of the empirical distribution, 
\item a CDF plot of both the empirical distribution and the fitted distribution, 
\item a Q-Q plot
representing the empirical quantiles (y-axis) against the theoretical quantiles (x-axis)
\item a P-P plot representing the empirical distribution function evaluated at each data point (y-axis)
against the fitted distribution function (x-axis).
\end{itemize}

For CDF, Q-Q and P-P plots, the probability plotting position is defined by default using Hazen's rule, with probability points of the empirical distribution calculated as
 `(1:n - 0.5)/n`, as recommended by `r citep(bib['Blom'])`.
This plotting position can be easily changed (see the reference 
manual for details `r citep(bib['fitdistrplus'])`.

# Additional graphic functions for a `"fitdist"` object

Unlike the generic `plot` function, the `denscomp`, `cdfcomp`,
`qqcomp` and `ppcomp` functions enable to draw separately each
of these four plots, in order to compare the empirical distribution 
and multiple parametric distributions fitted
on a same data set. These functions must be called with a first argument 
corresponding to a list of objects of class `fitdist`, and optionally
further arguments to customize the plot (see the reference 
manual for lists of arguments that may be specific to each plot `r citep(bib['fitdistrplus'])`. 
In the following example, we compare the fit of
a Weibull, a lognormal and a gamma distributions to the `groundbeef` data set (Figure~\ref{groundbeef:comp}).
```{r fitgroundbeef, fig.height=6, fig.width=6, echo=TRUE}
fg <- fitdist(groundbeef$serving, "gamma")
fln <- fitdist(groundbeef$serving, "lnorm")
par(mfrow = c(2, 2))
plot.legend <- c("Weibull", "lognormal", "gamma")
denscomp(list(fw, fln, fg), legendtext = plot.legend)
qqcomp(list(fw, fln, fg), legendtext = plot.legend)
cdfcomp(list(fw, fln, fg), legendtext = plot.legend)
ppcomp(list(fw, fln, fg), legendtext = plot.legend)
```





The density plot and the CDF plot may be considered as the basic classical goodness-of-fit plots.
The two other plots are complementary and can be very informative in some cases.
The Q-Q plot emphasizes the lack-of-fit at the distribution tails while the P-P plot emphasizes
the lack-of-fit at the distribution center.
In the present example (in Figure~\ref{groundbeef:comp}), none of the three fitted distributions correctly describes
the center of the distribution, but the Weibull and gamma distributions 
could be prefered for their better description of the right tail of the empirical distribution, especially
if this tail is important in the use of the fitted distribution, as it is in the context of
food risk assessment.


# Fitting non-R-base distribution

The data set named  `endosulfan` will now be used to illustrate other features of 
the \pkg{fitdistrplus} package. This data set contains
acute toxicity values for the organochlorine pesticide endosulfan
(geometric mean of LC50 ou EC50 values in $\mu g.L^{-1}$),
tested on Australian and non-Australian laboratory-species 
`r citep(bib['Hose04'])`. 

In ecotoxicology, a
lognormal or a loglogistic distribution is often fitted to such a data set in order
to characterize the species sensitivity distribution (SSD) for a pollutant. A low percentile
of the fitted distribution, generally the 5$\%$ percentile, is then calculated and named 
the hazardous concentration 5$\%$ (HC5). It is interpreted as the value of the
pollutant concentration protecting 95$\%$ of the species `r citep(bib['Posthuma2010'])`.
But the fit of a lognormal or a loglogistic distribution to the whole `endosulfan` data set is rather bad (Figure~\ref{endo:comp}),
especially due to a minority of very high values.

The two-parameter Pareto distribution and the three-parameter 
Burr distribution (which is an extension
of both the loglogistic and the Pareto distributions) have been fitted.
Pareto and Burr distributions are provided in the package \pkg{actuar}. 
Until here, we did not have to  define starting values (in the optimization process)
as reasonable starting values are implicity defined within the `fitdist` function 
for most of the distributions defined in \proglang{R} (see `?fitdist` for details).
For other distributions like the Pareto and the Burr distribution, initial 
values for the distribution parameters have to be supplied
in the argument `start`, as a named list  with initial values for each parameter 
(as they appear in the `d`, `p`, `q` functions). 
Having defined reasonable starting values\footnote{
The `plotdist` function can plot any 
parametric distribution with specified parameter values in argument `para`. It can thus help to find correct initial values for the distribution parameters in non trivial cases, by iterative calls if necessary (see the reference 
manual for examples `r citep(bib['fitdistrplus'])`.
}, 
various distributions can be fitted and graphically
compared. On this example, the function `cdfcomp` can be used to report CDF values in a logscale so as to emphasize discrepancies on the tail of
interest while defining an HC5 value (Figure~\ref{endo:comp}).


```{r fitendo, fig.height=5, fig.width=5, echo=TRUE}
data("endosulfan")
ATV <-endosulfan$ATV
fendo.ln <- fitdist(ATV, "lnorm")
library("actuar")
fendo.ll <- fitdist(ATV, "llogis", start = list(shape = 1, scale = 500))
fendo.P <- fitdist(ATV, "pareto", start = list(shape = 1, scale = 500))
fendo.B <- fitdist(ATV, "burr", start = list(shape1 = 0.3, shape2 = 1, 
  rate = 1))
```



None of the fitted distribution correctly
describes the right tail observed in the data set, but as shown in Figure~\ref{endo:comp},
the left-tail seems to be better described by the Burr distribution. Its use could then be considered
to estimate the HC5 value as the $5\%$ quantile of the distribution. This can be 
easily done using the `quantile` generic function defined for an object 
of class `"fitdist"`. Below is this calculation together with the calculation of the 
empirical quantile for comparison.

<<quantilefitdist, echo=TRUE, fig=FALSE>>=
```{r quantfitendo, echo=TRUE}
quantile(fendo.B, probs = 0.05)
quantile(ATV, probs = 0.05)
```

In addition to the ecotoxicology context, the `quantile` generic function is also attractive in
the actuarial--financial context. In fact, the value-at-risk $VAR_\alpha$ is defined as the $1-\alpha$-quantile
of the loss distribution and can be computed with `quantile` on a `"fitdist"` object.


# Goodness-of-fit statistics

The computation of different goodness-of-fit statistics is proposed in the \pkg{fitdistrplus} package
in order to further compare fitted distributions.
The purpose of goodness-of-fit statistics aims to measure the distance between the
fitted parametric distribution and the empirical distribution: e.g., 
the distance between the fitted cumulative distribution function $F$ 
and the empirical distribution function $F_{n}$.
When fitting continuous distributions, three  goodness-of-fit statistics are classicaly considered: 
Cramer-von Mises, Kolmogorov-Smirnov and Anderson-Darling statistics `r citep(bib['Stephens86'])`.
Naming $x_{i}$ the $n$ observations of a continuous variable $X$ arranged in an ascending order,
Table \ref{tabKSCvMAD} gives the definition and the empirical estimate of the three considered 
goodness-of-fit statistics.
They can be computed using the function `gofstat`
as defined by Stephens `r citep(bib['Stephens86'])`.



```{r fendo.gof.print, echo=TRUE, warning=FALSE}
gofstat(list(fendo.ln, fendo.ll, fendo.P, fendo.B),
  fitnames = c("lnorm", "llogis", "Pareto", "Burr"))
```

\begin{table}[htb!]
  \begin{center}
    \begin{tabular}{lll}
    \hline
      Statistic  & General formula & Computational formula\\
    \hline
      Kolmogorov-Smirnov   & $\sup|F_{n}(x) - F(x)|$ &
      $\max(D^{+},D^{-})$ with\\
      (KS) & &  $D^{+}=\max\limits_{i=1,\dots,n}\left(\frac{i}{n} - F_i\right)$ \\
           & &  $D^{-}=\max\limits_{i=1,\dots,n}\left(F_{i}-\frac{i-1}{n}\right)$ \\
    \hline
      Cramer-von Mises  & n $\int_{-\infty}^{\infty}(F_{n}(x) - F(x))^2 dx$ &
        $\frac{1}{12n} + \sum\limits_{i=1}^n \left(F_i-\frac{2i-1}{2n} \right)^{2}$\\
      (CvM)&&\\
% cvm <- 1/(12*n) + sum( ( theop - (2 * seq(1:n) - 1)/(2 * n) )^2 )
    \hline
      Anderson-Darling  & n $\int_{-\infty}^{\infty}\frac{(F_{n}(x) - F(x))^2}{F(x) (1 - F(x))} dx$
      & $-n -\frac{1}{n}\sum\limits_{i=1}^n (2i-1)\log(F_i(1-F_{n+1-i}))$ \\
      (AD) &    & \\
% ad <- - n - mean( (2 * seq(1:n) - 1) * (log(theop) + log(1 - rev(theop))) )
    \hline
     where $F_i\stackrel{\triangle}{=} F(x_i)$
    \end{tabular}
    \caption{Goodness-of-fit statistics as defined by Stephens `r citep(bib['Stephens86'])`.}
    \label{tabKSCvMAD}
  \end{center}
\end{table}


As giving  more weight to distribution tails, 
the Anderson-Darling statistic is of special interest when it matters to equally 
emphasize the tails as well as the main body of a distribution.
This is often the case in risk assessment `r citep(bib['Cullen99,Vose10'])`. For this reason, 
this statistics is often used to select the best distribution among those fitted.
Nevertheless, this statistics should be used cautiously when comparing fits of various distributions. 
Keeping in mind that the weighting of each CDF quadratic difference 
depends on the parametric distribution in its definition (see Table \ref{tabKSCvMAD}), 
Anderson-Darling statistics computed for several distributions fitted on a same data set
are theoretically difficult to compare. Moreover, such a statistic, as Cramer-von Mises and
Kolmogorov-Smirnov ones, does not take into account the complexity of 
the model (i.e., parameter number). It is not
a problem when compared distributions are characterized by the same number of parameters, but
it could systematically promote the selection of the more complex distributions in the other case. 
Looking at classical penalized criteria based on the loglikehood (AIC, BIC) seems thus also interesting, especially
to discourage overfitting. 

In the previous example, all the goodness-of-fit statistics based on the CDF distance are in favor of 
the Burr distribution, the only one characterized by three parameters, while AIC and BIC values
respectively give the preference to the Burr distribution or the Pareto distribution.
The choice between these two distributions seems thus less obvious and could be discussed. 
Even if specifically recommended for discrete distributions, the Chi-squared statistic may also be used for
continuous distributions (see Section~\ref{otherdata} and the reference 
manual for examples `r citep(bib['fitdistrplus'])`.


# Uncertainty in parameter estimates

The uncertainty in the parameters of the fitted distribution can be estimated by parametric or nonparametric
bootstraps using the `boodist` function for non-censored data `r citep(bib['efrontibshirani94'])`.
This function returns the bootstrapped values of parameters in an 
S3 class object which can be plotted to visualize the bootstrap region. 
The medians and the 95 percent confidence intervals of parameters (2.5 and 97.5 percentiles) are printed 
in the summary.
When inferior to the whole number of iterations (due to lack of convergence of the optimization
algorithm for some bootstrapped data sets), the number of iterations for which the estimation converges 
is also printed in the summary. 
    
The plot of an object of class `"bootdist"`
consists in a scatterplot or a matrix of scatterplots
of the bootstrapped values of parameters providing
a representation of the joint uncertainty distribution of the fitted parameters.
Below is an example of the use of the `bootdist` function with the previous fit of the Burr distribution to the
`endosulfan` data set (Figure~\ref{fig:bootstrap}). 
```{r fitllogisboot, fig.height=6, fig.width=6, echo=TRUE, warning=FALSE}
bendo.B <- bootdist(fendo.ll, niter = 1001)
summary(bendo.B)
```
```{r, eval=FALSE}
plot(bendo.B, enhance=TRUE)
```




Bootstrap samples of parameter estimates are useful especially to calculate confidence intervals on each parameter
of the fitted distribution from the marginal distribution of the bootstraped values. It is also interesting to look at the joint distribution of the bootstraped
values in a scatterplot (or a matrix of scatterplots if the number of parameters exceeds two) in order
to understand the potential structural correlation between parameters (see Figure~\ref{fig:bootstrap}).

The use of the whole bootstrap sample is also of interest in the risk assessment field. Its use enables
the characterization of uncertainty in distribution parameters. 
It can be directly used within a second-order Monte Carlo
simulation framework, especially within the package \pkg{mc2d} `r citep(bib['mc2d'])`. One could refer to `r citep(bib['Pouillot10'])` for an introduction to the use of \pkg{mc2d} 
and \pkg{fitdistrplus} packages in the context of quantitative 
risk assessment.

The bootstrap method can also be used to calculate confidence intervals on quantiles 
of the fitted distribution.
For this purpose, a generic `quantile` function is provided for class `bootdist`. 
By default, $95\%$ percentiles bootstrap confidence intervals of quantiles are provided.
Going back to the previous example from ecotoxicolgy, this function can be used to 
estimate the uncertainty associated to the HC5 estimation, for example from the previously fitted
Burr distribution to the `endosulfan` data set.
```{r fitATVlnormquant, fig.height=5, fig.width=5, echo=TRUE, warning=FALSE}
quantile(bendo.B, probs = 5:10/100)
```

# References





